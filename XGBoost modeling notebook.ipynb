{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRv8adCyfT6f"
   },
   "source": [
    "# **Telecom Machine Learning Project to Predict Customer Churn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXZnQ0Q5eo-e"
   },
   "source": [
    "## **Business Overview**\n",
    "\n",
    "The telecommunications industry is a rapidly growing sector that is constantly evolving to meet the demands of consumers. As technology advances and user behavior changes, telecom operators face a variety of challenges that can impact their business success. In order to stay competitive and meet customer needs, it is important for telecom companies to regularly analyze their data to identify relevant problems and opportunities for improvement.\n",
    "\n",
    "**Aim:**\n",
    "\n",
    "The aim of a churn prediction notebook is to develop a machine learning model that can predict which customers are likely to churn or discontinue their use of a service or product. Churn prediction is a critical business problem for companies that operate on a subscription or recurring revenue model, such as telecommunications companies. \n",
    "\n",
    "While the project will involve building a churn prediction model, an additional focus will be on the importance of monitoring and adapting to changes in the data that may affect the accuracy and effectiveness of the model over time. The project will also emphasize the need for a feedback loop that allows for continuous improvement and refinement of the model based on new data and changing business requirements. By highlighting these concepts, the project aims to help businesses understand the importance of staying agile and adaptable in their machine learning approaches, rather than solely focusing on the accuracy of a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yaKuQlUUooQ"
   },
   "source": [
    "## Understanding Churn Prediction\n",
    "\n",
    "Churn prediction involves identifying customers likely to stop using a product or service. Specifically, in telecommunications, it's about detecting customers inclined to switch providers or end their current contracts.\n",
    "\n",
    "This prediction is vital for telecom companies due to its direct effect on revenue and profit. The telecom industry is fiercely competitive, and understanding which customers might leave is crucial. It enables providers to proactively work on retaining these customers.\n",
    "\n",
    "## Key Challenges\n",
    "\n",
    "- Analyzing vast, varied data sources is a primary challenge in churn prediction. Telecom companies accumulate huge data from customer interactions, network operations, and billing, often stored separately, complicating comprehensive analysis.\n",
    "  \n",
    "- Understanding diverse customer behaviors is another hurdle. Customers leave for various reasons, like service quality or better offers elsewhere. Accurately predicting churn requires grasping these varied behaviors and pinpointing key churn indicators.\n",
    "\n",
    "## Impact on Business\n",
    "\n",
    "Churn prediction significantly influences telecom business operations. High churn rates can erode revenue and profit, while effective prediction models can help in retaining at-risk customers. Here are essential business impacts:\n",
    "\n",
    "- **Safeguarding Revenue**: Identifying potential churn helps in taking actions like offering promotions or service upgrades to keep customers, thus protecting revenue and reducing new customer acquisition costs.\n",
    "\n",
    "- **Boosting Customer Retention**: By pinpointing customer departure reasons, telecom companies can enhance their services, fostering loyalty and increasing customer lifetime value.\n",
    "\n",
    "- **Cutting Costs**: It's cheaper to retain existing customers than acquire new ones. Churn prediction allows for more focused and efficient marketing strategies.\n",
    "\n",
    "- **Gaining Competitive Edge**: Effective churn management can set a telecom company apart, helping to grow market share and profitability by improving customer satisfaction and loyalty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdkeckhCKFMo"
   },
   "source": [
    "## **Approach**\n",
    "\n",
    "**Data exploration**\n",
    "\n",
    "* Load the dataset and examine its structure and contents.\n",
    "* Explore the distribution of the target variable (churn) and the features.\n",
    "\n",
    "**Data preprocessing**\n",
    "\n",
    "* Handle missing values by imputing them with appropriate values.\n",
    "* Handle outliers by removing or transforming them.\n",
    "* Encode categorical variables using one-hot encoding.\n",
    "* Scale numerical variables using Standard scaler.\n",
    "\n",
    "\n",
    "**Model training**\n",
    "\n",
    "* Split the data into training and validation sets.\n",
    "* Train logistic regression, random forest, and XGBoost models on the training set.\n",
    "* Evaluate the performance of the models on the validation set using metrics such as accuracy, precision, recall, and F1 score.\n",
    "* Choose the best-performing model based on the evaluation results.\n",
    "\n",
    "**Data drift monitoring**\n",
    "\n",
    "* Use deep checks to monitor for data drift in the input features and the target variable.\n",
    "* Check the model's performance on the validation set regularly to detect any model drift.\n",
    "\n",
    "**Inference pipeline**\n",
    "\n",
    "* Build an inference pipeline to predict churn for new data.\n",
    "* Handle cases where the label (churn) is not present in the input data.\n",
    "* Handle cases where the drift is detected by retraining the model with misclassified data.\n",
    "\n",
    "**Project Summary**\n",
    "\n",
    "* Summarize the results and draw insights from the model's predictions.\n",
    "* Provide recommendations for business actions based on the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUdQ82V3M_-R"
   },
   "source": [
    "## **Package Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2KU4tEjC15Jr"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nbG5fh1i9Q3U"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from projectpro import preserve, save_point, model_snapshot, feedback, show_video \n",
    "import math\n",
    "import sys\n",
    "import traceback\n",
    "from deepchecks.tabular import Dataset\n",
    "from deepchecks.tabular import Suite\n",
    "from deepchecks.tabular.checks import WholeDatasetDrift, DataDuplicates, NewLabelTrainTest, TrainTestFeatureDrift, TrainTestLabelDrift\n",
    "from deepchecks.tabular.checks import FeatureLabelCorrelation, FeatureLabelCorrelationChange, ConflictingLabels, OutlierSampleDetection \n",
    "from deepchecks.tabular.checks import WeakSegmentsPerformance, RocReport, ConfusionMatrixReport, TrainTestPredictionDrift, CalibrationScore, BoostingOverfit\n",
    "from sklearn.metrics import f1_score, recall_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pickle import dump\n",
    "from sklearn.impute import SimpleImputer\n",
    "# import xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "preserve(\"fcTel2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-I2Xd4o4uKB"
   },
   "source": [
    "## **Data Reading from Different Sources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0cGA-Er4Z-2i"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5WNyymnhZ-2i"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/Telecom__Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBC_yfBlN3mc"
   },
   "source": [
    "## **Data Exploration**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9Fqx0MsIZ-2j",
    "outputId": "14d978e0-75fa-4237-b17a-3c8d16c57c06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653435, 77)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the Dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gMm321OAZ-2k",
    "outputId": "254a55b1-2d79-4906-8ca8-78a837b0685c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 653435 entries, 0 to 653434\n",
      "Data columns (total 77 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Customer ID                 653435 non-null  object \n",
      " 1   Month                       653435 non-null  int64  \n",
      " 2   Month of Joining            653435 non-null  float64\n",
      " 3   zip_code                    653435 non-null  int64  \n",
      " 4   Gender                      653435 non-null  object \n",
      " 5   Age                         653435 non-null  float64\n",
      " 6   Married                     653435 non-null  object \n",
      " 7   Dependents                  653435 non-null  object \n",
      " 8   Number of Dependents        648501 non-null  float64\n",
      " 9   Location ID                 653435 non-null  object \n",
      " 10  Service ID                  653435 non-null  object \n",
      " 11  state                       653435 non-null  object \n",
      " 12  county                      653435 non-null  object \n",
      " 13  timezone                    653435 non-null  object \n",
      " 14  area_codes                  653435 non-null  object \n",
      " 15  country                     653435 non-null  object \n",
      " 16  latitude                    653435 non-null  float64\n",
      " 17  longitude                   653435 non-null  float64\n",
      " 18  arpu                        653435 non-null  float64\n",
      " 19  roam_ic                     653435 non-null  float64\n",
      " 20  roam_og                     653435 non-null  float64\n",
      " 21  loc_og_t2t                  653435 non-null  float64\n",
      " 22  loc_og_t2m                  653435 non-null  float64\n",
      " 23  loc_og_t2f                  653435 non-null  float64\n",
      " 24  loc_og_t2c                  653435 non-null  float64\n",
      " 25  std_og_t2t                  653435 non-null  float64\n",
      " 26  std_og_t2m                  653435 non-null  float64\n",
      " 27  std_og_t2f                  653435 non-null  float64\n",
      " 28  std_og_t2c                  653435 non-null  float64\n",
      " 29  isd_og                      653435 non-null  float64\n",
      " 30  spl_og                      653435 non-null  float64\n",
      " 31  og_others                   653435 non-null  float64\n",
      " 32  loc_ic_t2t                  653435 non-null  float64\n",
      " 33  loc_ic_t2m                  653435 non-null  float64\n",
      " 34  loc_ic_t2f                  653435 non-null  float64\n",
      " 35  std_ic_t2t                  653435 non-null  float64\n",
      " 36  std_ic_t2m                  653435 non-null  float64\n",
      " 37  std_ic_t2f                  653435 non-null  float64\n",
      " 38  std_ic_t2o                  653435 non-null  float64\n",
      " 39  spl_ic                      653435 non-null  float64\n",
      " 40  isd_ic                      653435 non-null  float64\n",
      " 41  ic_others                   653435 non-null  float64\n",
      " 42  total_rech_amt              653435 non-null  float64\n",
      " 43  total_rech_data             653435 non-null  float64\n",
      " 44  vol_4g                      653435 non-null  float64\n",
      " 45  vol_5g                      653435 non-null  float64\n",
      " 46  arpu_5g                     653435 non-null  float64\n",
      " 47  arpu_4g                     653435 non-null  float64\n",
      " 48  night_pck_user              653435 non-null  float64\n",
      " 49  fb_user                     653435 non-null  float64\n",
      " 50  aug_vbc_5g                  653435 non-null  float64\n",
      " 51  Churn Value                 653435 non-null  int64  \n",
      " 52  Referred a Friend           653435 non-null  object \n",
      " 53  Number of Referrals         653048 non-null  float64\n",
      " 54  Phone Service               653435 non-null  object \n",
      " 55  Multiple Lines              607374 non-null  object \n",
      " 56  Internet Service            653435 non-null  object \n",
      " 57  Internet Type               328357 non-null  object \n",
      " 58  Streaming Data Consumption  653435 non-null  int64  \n",
      " 59  Online Security             653435 non-null  object \n",
      " 60  Online Backup               653435 non-null  object \n",
      " 61  Device Protection Plan      653435 non-null  object \n",
      " 62  Premium Tech Support        653435 non-null  object \n",
      " 63  Streaming TV                653435 non-null  object \n",
      " 64  Streaming Movies            653435 non-null  object \n",
      " 65  Streaming Music             653435 non-null  object \n",
      " 66  Unlimited Data              642339 non-null  object \n",
      " 67  Payment Method              653435 non-null  object \n",
      " 68  Status ID                   653435 non-null  object \n",
      " 69  Satisfaction Score          653435 non-null  int64  \n",
      " 70  Churn Category              653435 non-null  object \n",
      " 71  Churn Reason                653435 non-null  object \n",
      " 72  Customer Status             653435 non-null  object \n",
      " 73  offer                       653435 non-null  object \n",
      " 74  age_bucket                  653435 non-null  object \n",
      " 75  rank                        653435 non-null  float64\n",
      " 76  rank_x                      653435 non-null  float64\n",
      "dtypes: float64(41), int64(5), object(31)\n",
      "memory usage: 383.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the Information of the Dataframe, datatypes and non-null counts\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Uyb0dMULZ-2k",
    "outputId": "b1062bd9-8e17-4fc6-c663-5fb75902c6f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer ID', 'Month', 'Month of Joining', 'zip_code', 'Gender', 'Age',\n",
       "       'Married', 'Dependents', 'Number of Dependents', 'Location ID',\n",
       "       'Service ID', 'state', 'county', 'timezone', 'area_codes', 'country',\n",
       "       'latitude', 'longitude', 'arpu', 'roam_ic', 'roam_og', 'loc_og_t2t',\n",
       "       'loc_og_t2m', 'loc_og_t2f', 'loc_og_t2c', 'std_og_t2t', 'std_og_t2m',\n",
       "       'std_og_t2f', 'std_og_t2c', 'isd_og', 'spl_og', 'og_others',\n",
       "       'loc_ic_t2t', 'loc_ic_t2m', 'loc_ic_t2f', 'std_ic_t2t', 'std_ic_t2m',\n",
       "       'std_ic_t2f', 'std_ic_t2o', 'spl_ic', 'isd_ic', 'ic_others',\n",
       "       'total_rech_amt', 'total_rech_data', 'vol_4g', 'vol_5g', 'arpu_5g',\n",
       "       'arpu_4g', 'night_pck_user', 'fb_user', 'aug_vbc_5g', 'Churn Value',\n",
       "       'Referred a Friend', 'Number of Referrals', 'Phone Service',\n",
       "       'Multiple Lines', 'Internet Service', 'Internet Type',\n",
       "       'Streaming Data Consumption', 'Online Security', 'Online Backup',\n",
       "       'Device Protection Plan', 'Premium Tech Support', 'Streaming TV',\n",
       "       'Streaming Movies', 'Streaming Music', 'Unlimited Data',\n",
       "       'Payment Method', 'Status ID', 'Satisfaction Score', 'Churn Category',\n",
       "       'Churn Reason', 'Customer Status', 'offer', 'age_bucket', 'rank',\n",
       "       'rank_x'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the names of the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXTBcfTrORWl"
   },
   "source": [
    "## **Data Dictionary (out of order)** \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Column name\t | Description|\n",
    "| ----- | ----- |\n",
    "| Customer ID\t | Unique identifier for each customer |\n",
    "| Month | Calendar Month- 1:12 | \n",
    "| Month of Joining |\tCalender Month -1:14, Month for which the data is captured|\n",
    "| zip_code |\tZip Code|\n",
    "|Gender |\tGender|\n",
    "| Age |\tAge(Years)|\n",
    "| Married |\tMarital Status |\n",
    "|Dependents | Dependents - Binary |\n",
    "| Number of Dependents |\tNumber of Dependents|\n",
    "|Location ID |\tLocation ID|\n",
    "|Service ID\t |Service ID|\n",
    "|state|\tState|\n",
    "|county\t|County|\n",
    "|timezone\t|Timezone|\n",
    "|area_codes|\tArea Code|\n",
    "|country\t|Country|\n",
    "|latitude|\tLatitude|\n",
    "|longitude\t|Longitude|\n",
    "|arpu|\tAverage revenue per user|\n",
    "|roam_ic\t|Roaming incoming calls in minutes|\n",
    "|roam_og\t|Roaming outgoing calls in minutes|\n",
    "|loc_og_t2t|\tLocal outgoing calls within same network in minutes|\n",
    "|loc_og_t2m\t|Local outgoing calls outside network in minutes(outside same + partner network)|\n",
    "|loc_og_t2f|\tLocal outgoing calls with Partner network in minutes|\n",
    "|loc_og_t2c\t|Local outgoing calls with Call Center in minutes|\n",
    "|std_og_t2t|\tSTD outgoing calls within same network in minutes|\n",
    "|std_og_t2m|\tSTD outgoing calls outside network in minutes(outside same + partner network)|\n",
    "|std_og_t2f|\tSTD outgoing calls with Partner network in minutes|\n",
    "|std_og_t2c\t|STD outgoing calls with Call Center in minutes|\n",
    "|isd_og|\tISD Outgoing calls|\n",
    "|spl_og\t|Special Outgoing calls|\n",
    "|og_others|\tOther Outgoing Calls|\n",
    "|loc_ic_t2t|\tLocal incoming calls within same network in minutes|\n",
    "|loc_ic_t2m|\tLocal incoming calls outside network in minutes(outside same + partner network)|\n",
    "|loc_ic_t2f\t|Local incoming calls with Partner network in minutes|\n",
    "|std_ic_t2t\t|STD incoming calls within same network in minutes|\n",
    "|std_ic_t2m\t|STD incoming calls outside network in minutes(outside same + partner network)|\n",
    "|std_ic_t2f|\tSTD incoming calls with Partner network in minutes|\n",
    "|std_ic_t2o|\tSTD incoming calls operators other networks in minutes|\n",
    "|spl_ic|\tSpecial Incoming calls in minutes|\n",
    "|isd_ic|\tISD Incoming calls in minutes|\n",
    "|ic_others|\tOther Incoming Calls|\n",
    "|total_rech_amt|\tTotal Recharge Amount in Local Currency|\n",
    "|total_rech_data|\tTotal Recharge Amount for Data in Local Currency\n",
    "|vol_4g|\t4G Internet Used in GB|\n",
    "|vol_5g|\t5G Internet used in GB|\n",
    "|arpu_5g|\tAverage revenue per user over 5G network|\n",
    "|arpu_4g|\tAverage revenue per user over 4G network|\n",
    "|night_pck_user|\tIs Night Pack User(Specific Scheme)|\n",
    "|fb_user|\tSocial Networking scheme|\n",
    "|aug_vbc_5g|\tVolume Based cost for 5G network (outside the scheme paid based on extra usage)|\n",
    "|offer|\tOffer Given to User|\n",
    "|Referred a Friend|\tReferred a Friend : Binary|\n",
    "|Number of Referrals|\tNumber of Referrals|\n",
    "|Phone Service|\tPhone Service: Binary|\n",
    "|Multiple Lines|\tMultiple Lines for phone service: Binary|\n",
    "|Internet Service|\tInternet Service: Binary|\n",
    "|Internet Type|\tInternet Type|\n",
    "|Streaming Data Consumption|\tStreaming Data Consumption|\n",
    "|Online Security|\tOnline Security|\n",
    "|Online Backup|\tOnline Backup|\n",
    "|Device Protection Plan|\tDevice Protection Plan|\n",
    "|Premium Tech Support|\tPremium Tech Support|\n",
    "|Streaming TV|\tStreaming TV|\n",
    "|Streaming Movies|\tStreaming Movies|\n",
    "|Streaming Music|\tStreaming Music|\n",
    "|Unlimited Data|\tUnlimited Data|\n",
    "|Payment Method|\tPayment Method|\n",
    "|Status ID|\tStatus ID|\n",
    "|Satisfaction Score|\tSatisfaction Score|\n",
    "|Churn Category|\tChurn Category|\n",
    "|Churn Reason|\tChurn Reason|\n",
    "|Customer Status|\tCustomer Status|\n",
    "|Churn Value|\tBinary Churn Value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CYI9w9ZQZ-2k",
    "outputId": "c86cad26-af70-4576-a9dc-8a57e304bc82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID         0\n",
       "Month               0\n",
       "Month of Joining    0\n",
       "zip_code            0\n",
       "Gender              0\n",
       "                   ..\n",
       "Customer Status     0\n",
       "offer               0\n",
       "age_bucket          0\n",
       "rank                0\n",
       "rank_x              0\n",
       "Length: 77, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values sum\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_P-B9TxjZ-2l",
    "outputId": "a1dca556-b0c6-4292-edb2-5ee1f7293325"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values in total recharge data\n",
    "df['total_rech_data'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zFPE07KUZ-2l",
    "outputId": "09b90153-2724-4faf-ffd7-d9540cf7de48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325078"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values in Internet Type\n",
    "df['Internet Type'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "20Xrd0RHZ-2l",
    "outputId": "0d715b22-e433-4087-f308-49c741ac242e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing value percentage\n",
    "df['total_rech_data'].isna().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmWVmQQXZ-2l"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "*  These missing values may represent customers who have not recharged their account or have recharged but the information has not been recorded.\n",
    "\n",
    "* It is possible that customers with missing recharge data are those who received free data service, and therefore did not need to recharge their account. Alternatively, it is possible that the missing values are due to technical issues, such as data recording errors or system failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vvV6-BuZZ-2m",
    "outputId": "dedf9d49-79e2-42d3-d983-3f767b915de8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the value counts of Internet Service where total recharge data was null\n",
    "df[df['total_rech_data'].isna()]['Internet Service'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR2RpuGKZ-2m"
   },
   "source": [
    "**Observation**:\n",
    "\n",
    "* It turns out that all customers with missing recharge data have opted for internet service, the next step could be to check if they have used it or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PBgsjUoPZ-2m",
    "outputId": "aa6246b9-4066-4422-b758-25c283ef8546"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check unlimited data column\n",
    "df[(df['total_rech_data'].isna())]['Unlimited Data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fVj27H0xZ-2m",
    "outputId": "15ef3fdf-b711-499d-d52f-db9e2d51b477"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check Average Revenue for 4g and 5g\n",
    "df[(df['total_rech_data'].isna())][['arpu_4g','arpu_5g']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z--ECzlXZ-2m"
   },
   "source": [
    "**Observation**:\n",
    "\n",
    "* We can fill the missing values in the total_rech_data column with 0 when the arpu (Average Revenue Per User) is not applicable. This is because the arpu is a measure of the revenue generated per user, and if it is not applicable, it may indicate that the user is not generating any revenue for the company. In such cases, it is reasonable to assume that the total recharge amount is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HKsHAQQcZ-2n",
    "outputId": "8c982b59-e751-4ed1-8e8f-ca437e26f0af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arpu_4g    arpu_5g      \n",
       "0.00       0.000000         379093\n",
       "           63.000000         13018\n",
       "63.00      0.000000          12966\n",
       "254687.00  0.000000          10909\n",
       "0.00       254687.000000     10707\n",
       "                             ...  \n",
       "250.33     8529.715094           1\n",
       "250.34     41.520000             1\n",
       "250.35     130.170000            1\n",
       "           182.760000            1\n",
       "838.75     2111.580000           1\n",
       "Name: count, Length: 195759, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value counts of ARPU 4g and 5g\n",
    "df[['arpu_4g','arpu_5g']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XHibU4lcZ-2n"
   },
   "outputs": [],
   "source": [
    "# Replacing all values of total recharge data= 0 where arpu 4g and 5g are not applicable\n",
    "df.loc[(df['arpu_4g']=='Not Applicable') | (df['arpu_5g']=='Not Applicable'),'total_rech_data']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5ZywhbWfZ-2n",
    "outputId": "66d9b527-8b00-46ce-b36b-bd25ba1e8ded"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing value percentage\n",
    "df['total_rech_data'].isna().sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvS-GOYdZ-2n"
   },
   "source": [
    "We cannot fill other values with 0 because they have some ARPU to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3xivTAuUZ-2n",
    "outputId": "db7a1b71-ca02-478f-eb06-751e1df76303"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2949413484126193"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean of 'total_rech_data' where either 'arpu_4g' or 'arpu_5g' is not equal to 'Not Applicable'\n",
    "df.loc[(df['arpu_4g']!='Not Applicable') | (df['arpu_5g']!='Not Applicable'),'total_rech_data'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5NNUYX8Z-2n"
   },
   "source": [
    "With this mean, we will fill the NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ePxg16ZkZ-2n"
   },
   "outputs": [],
   "source": [
    "# Fill NaN values in 'total_rech_data' with the mean of 'total_rech_data' where either 'arpu_4g' or 'arpu_5g' is not equal to 'Not Applicable'\n",
    "df['total_rech_data']=df['total_rech_data'].fillna(df.loc[(df['arpu_4g']!='Not Applicable') | (df['arpu_5g']!='Not Applicable'),'total_rech_data'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2y8-hQOgZ-2n",
    "outputId": "73731371-748c-4dd8-a9f0-dab769c9d4e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Internet Type\n",
       "NaN            325078\n",
       "Fiber Optic    134929\n",
       "Cable          112061\n",
       "DSL             81367\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value counts for Internet Type\n",
    "df['Internet Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "VojpiRlLZ-2o",
    "outputId": "423ee788-6a6a-447d-fa27-14efb280d6ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Internet Service\n",
       "No     236017\n",
       "Yes     89061\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check value counts for Internet Service where Internet Type is null\n",
    "df[df['Internet Type'].isna()]['Internet Service'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDvmPBoeZ-2o"
   },
   "source": [
    "All null values in Internet Type does not have Internet Service. Let's fill these null values with Not Applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "YjmE5bcbZ-2o"
   },
   "outputs": [],
   "source": [
    "# Filling Null values in Internet Type \n",
    "df['Internet Type']=df['Internet Type'].fillna('Not Applicable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BoezoPLWZ-2o",
    "outputId": "9efd88a7-4612-40ab-eaa0-24a7635e19ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653435, 77)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "WjO5_qGIZ-2o"
   },
   "outputs": [],
   "source": [
    "# Insert a new column named 'total_recharge' before the last column in the dataframe \n",
    "# The values of 'total_recharge' are the sum of 'total_rech_amt' and 'total_rech_data'\n",
    "df.insert(loc=df.shape[1]-1,column='total_recharge',value=df['total_rech_amt']+df['total_rech_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wkQYshrQZ-2o",
    "outputId": "4940c1b4-7a6a-407a-d9a3-b8e76325466f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multiple Lines</th>\n",
       "      <td>7.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unlimited Data</th>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Dependents</th>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Referrals</th>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer ID</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2m</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2t</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2c</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2f</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_x</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      null\n",
       "Multiple Lines        7.05\n",
       "Unlimited Data        1.70\n",
       "Number of Dependents  0.76\n",
       "Number of Referrals   0.06\n",
       "Customer ID           0.00\n",
       "...                    ...\n",
       "std_og_t2m            0.00\n",
       "std_og_t2t            0.00\n",
       "loc_og_t2c            0.00\n",
       "loc_og_t2f            0.00\n",
       "rank_x                0.00\n",
       "\n",
       "[78 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking percent of missing values in columns\n",
    "df_missing_columns = (round(((df.isnull().sum()/len(df.index))*100),2).to_frame('null')).sort_values('null', ascending=False)\n",
    "df_missing_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHK6wY6OZ-2o"
   },
   "source": [
    "Let's drop some unnecessary columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PRayCzDDZ-2o"
   },
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "df=df.drop(columns=['night_pck_user', 'fb_user','Churn Category','Churn Reason', 'Customer Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "kCVlehSCZ-2o",
    "outputId": "1603cc56-12b2-45d4-f538-b6f7bd8c3d34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.57"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking churn %\n",
    "round(100*(df['Churn Value'].mean()),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "3d99fGw_Z-2p",
    "outputId": "21c70fea-cdc9-41e0-be0b-e260bcd7244c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1096"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique latitudes\n",
    "df['latitude'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1cHkBum8Z-2p",
    "outputId": "3575ab63-3f7b-4235-8e2f-79301e2a16de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique longitudes\n",
    "df['longitude'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indices = df[df['Number of Dependents'].isna()].index\n",
    "\n",
    "# Randomly select half of the indices\n",
    "random_half = np.random.choice(nan_indices, size=len(nan_indices)//2, replace=False)\n",
    "\n",
    "# Assign 0 to the selected half\n",
    "df.loc[random_half, 'Number of Dependents'] = 0\n",
    "\n",
    "# Assign 1 to the remaining NaN values\n",
    "df['Number of Dependents'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Mp5w1niZ-2p"
   },
   "source": [
    "Replace 'Not Applicable' with 0 in both 'arpu_4g' and 'arpu_5g'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "74bP-j3tZ-2p"
   },
   "outputs": [],
   "source": [
    "# Replace 'Not Applicable' with 0 in 'arpu_4g'\n",
    "df['arpu_4g'] = df['arpu_4g'].replace('Not Applicable', 0)\n",
    "\n",
    "# Replace 'Not Applicable' with 0 in 'arpu_5g'\n",
    "df['arpu_5g'] = df['arpu_5g'].replace('Not Applicable', 0)\n",
    "\n",
    "# Convert 'arpu_4g' to float data type\n",
    "df['arpu_4g'] = df['arpu_4g'].astype(float)\n",
    "\n",
    "# Convert 'arpu_5g' to float data type\n",
    "df['arpu_5g'] = df['arpu_5g'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "NypxsZ4JZ-2p",
    "outputId": "2ae94d49-c660-4465-d701-d51b5d0931fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID          object\n",
       "Month                 int64\n",
       "Month of Joining    float64\n",
       "zip_code              int64\n",
       "Gender               object\n",
       "                     ...   \n",
       "offer                object\n",
       "age_bucket           object\n",
       "rank                float64\n",
       "total_recharge      float64\n",
       "rank_x              float64\n",
       "Length: 73, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-HS3WicKZ-2p"
   },
   "outputs": [],
   "source": [
    "# Note: We are keeping customer location-based attributes aside for now\n",
    "location_att=['zip_code''state', 'county', 'timezone', 'area_codes', 'country','latitude','longitude']\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_cols=['Gender',\n",
    "       'Married', 'Dependents',\n",
    "       'offer','Referred a Friend', 'Phone Service',\n",
    "       'Multiple Lines', 'Internet Service', 'Internet Type',\n",
    "        'Online Security', 'Online Backup',\n",
    "       'Device Protection Plan', 'Premium Tech Support', 'Streaming TV',\n",
    "       'Streaming Movies', 'Streaming Music', 'Unlimited Data',\n",
    "       'Payment Method']\n",
    "\n",
    "# List of continuous columns\n",
    "cts_cols=['Age','Number of Dependents',\n",
    "       'roam_ic', 'roam_og', 'loc_og_t2t',\n",
    "       'loc_og_t2m', 'loc_og_t2f', 'loc_og_t2c', 'std_og_t2t', 'std_og_t2m',\n",
    "       'std_og_t2f', 'std_og_t2c', 'isd_og', 'spl_og', 'og_others',\n",
    "       'loc_ic_t2t', 'loc_ic_t2m', 'loc_ic_t2f', 'std_ic_t2t', 'std_ic_t2m',\n",
    "       'std_ic_t2f', 'std_ic_t2o', 'spl_ic', 'isd_ic', 'ic_others',\n",
    "       'total_rech_amt', 'total_rech_data', 'vol_4g', 'vol_5g', 'arpu_5g',\n",
    "       'arpu_4g', 'arpu', 'aug_vbc_5g', 'Number of Referrals','Satisfaction Score',\n",
    "       'Streaming Data Consumption']   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFRSmmv015Jz"
   },
   "source": [
    "## Outlier detection\n",
    "\n",
    "By calculating quantiles for each continuous variable in the dataset, we are trying to get an idea about the spread and distribution of the data. Specifically, we are interested in identifying potential outliers in the data.\n",
    "\n",
    "Quantiles divide a distribution into equal proportions. For instance, the 0.25 quantile is the value below which 25% of the observations fall and the 0.75 quantile is the value below which 75% of the observations fall. By calculating quantiles at various levels, we can get a better understanding of the distribution of the data and identify any observations that are too far away from the rest of the data.\n",
    "\n",
    "These quantiles can be used as thresholds to identify potential outliers in the data. Observations with values beyond these thresholds can be considered as potential outliers and further investigation can be carried out to determine if they are true outliers or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "LqaJC1SzZ-2p"
   },
   "outputs": [],
   "source": [
    "# Create an empty dataframe with columns as cts_cols and index as quantiles\n",
    "quantile_df=pd.DataFrame(columns=cts_cols,index=[0.1,0.25,0.5,0.75,0.8,0.9,0.95,0.97,0.99])\n",
    "\n",
    "# for each column in cts_cols, calculate the corresponding quantiles and store them in the quantile_df\n",
    "for col in cts_cols:\n",
    "   quantile_df[col]=df[col].quantile([0.1,0.25,0.5,0.75,0.8,0.9,0.95,0.97,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "fH6bWCegZ-2p",
    "outputId": "8ed6f768-73a7-4c99-c71c-fe22ca8abdd3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>roam_ic</th>\n",
       "      <th>roam_og</th>\n",
       "      <th>loc_og_t2t</th>\n",
       "      <th>loc_og_t2m</th>\n",
       "      <th>loc_og_t2f</th>\n",
       "      <th>loc_og_t2c</th>\n",
       "      <th>std_og_t2t</th>\n",
       "      <th>std_og_t2m</th>\n",
       "      <th>std_og_t2f</th>\n",
       "      <th>std_og_t2c</th>\n",
       "      <th>isd_og</th>\n",
       "      <th>spl_og</th>\n",
       "      <th>og_others</th>\n",
       "      <th>loc_ic_t2t</th>\n",
       "      <th>loc_ic_t2m</th>\n",
       "      <th>loc_ic_t2f</th>\n",
       "      <th>std_ic_t2t</th>\n",
       "      <th>std_ic_t2m</th>\n",
       "      <th>std_ic_t2f</th>\n",
       "      <th>std_ic_t2o</th>\n",
       "      <th>spl_ic</th>\n",
       "      <th>isd_ic</th>\n",
       "      <th>ic_others</th>\n",
       "      <th>total_rech_amt</th>\n",
       "      <th>total_rech_data</th>\n",
       "      <th>vol_4g</th>\n",
       "      <th>vol_5g</th>\n",
       "      <th>arpu_5g</th>\n",
       "      <th>arpu_4g</th>\n",
       "      <th>arpu</th>\n",
       "      <th>aug_vbc_5g</th>\n",
       "      <th>Number of Referrals</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Streaming Data Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.7400</td>\n",
       "      <td>33.790000</td>\n",
       "      <td>14.460000</td>\n",
       "      <td>16.950000</td>\n",
       "      <td>13.060000</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10.770000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-256.2000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.080000</td>\n",
       "      <td>14.7000</td>\n",
       "      <td>32.6950</td>\n",
       "      <td>26.260000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>33.120000</td>\n",
       "      <td>25.550000</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>4.940000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>85.5650</td>\n",
       "      <td>84.170000</td>\n",
       "      <td>36.120000</td>\n",
       "      <td>42.460000</td>\n",
       "      <td>32.190000</td>\n",
       "      <td>12.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>26.980000</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>72.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.9600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.560000</td>\n",
       "      <td>75.1000</td>\n",
       "      <td>171.3300</td>\n",
       "      <td>135.460000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>8.180000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>134.800000</td>\n",
       "      <td>6.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.190000</td>\n",
       "      <td>25.580000</td>\n",
       "      <td>17.830000</td>\n",
       "      <td>171.5000</td>\n",
       "      <td>168.390000</td>\n",
       "      <td>72.060000</td>\n",
       "      <td>84.470000</td>\n",
       "      <td>64.760000</td>\n",
       "      <td>24.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>53.700000</td>\n",
       "      <td>40.540000</td>\n",
       "      <td>374.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.010</td>\n",
       "      <td>274.1400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>348.5400</td>\n",
       "      <td>117.360000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>162.060000</td>\n",
       "      <td>135.2900</td>\n",
       "      <td>309.0900</td>\n",
       "      <td>618.310000</td>\n",
       "      <td>14.090000</td>\n",
       "      <td>14.700068</td>\n",
       "      <td>316.240000</td>\n",
       "      <td>244.510000</td>\n",
       "      <td>36.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.140000</td>\n",
       "      <td>46.190000</td>\n",
       "      <td>106.790000</td>\n",
       "      <td>1259.2650</td>\n",
       "      <td>1090.100000</td>\n",
       "      <td>496.805000</td>\n",
       "      <td>126.280000</td>\n",
       "      <td>448.831338</td>\n",
       "      <td>186.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>80.380000</td>\n",
       "      <td>60.730000</td>\n",
       "      <td>1089.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>154.910</td>\n",
       "      <td>895.8550</td>\n",
       "      <td>194.630000</td>\n",
       "      <td>228.400000</td>\n",
       "      <td>580.6550</td>\n",
       "      <td>311.760000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>496.940126</td>\n",
       "      <td>146.8200</td>\n",
       "      <td>856.8840</td>\n",
       "      <td>1393.012469</td>\n",
       "      <td>43.886016</td>\n",
       "      <td>15.970000</td>\n",
       "      <td>344.970000</td>\n",
       "      <td>266.550000</td>\n",
       "      <td>71.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.910000</td>\n",
       "      <td>50.240000</td>\n",
       "      <td>229.242068</td>\n",
       "      <td>1999.5880</td>\n",
       "      <td>1471.763855</td>\n",
       "      <td>653.084534</td>\n",
       "      <td>543.225916</td>\n",
       "      <td>634.160224</td>\n",
       "      <td>275.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>384.901558</td>\n",
       "      <td>64.800000</td>\n",
       "      <td>2197.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>176.360</td>\n",
       "      <td>1655.2720</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>783.452000</td>\n",
       "      <td>626.2400</td>\n",
       "      <td>350.531298</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>55.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>969.100000</td>\n",
       "      <td>689.4660</td>\n",
       "      <td>3613.8880</td>\n",
       "      <td>2644.684000</td>\n",
       "      <td>126.618596</td>\n",
       "      <td>109.120000</td>\n",
       "      <td>1547.248709</td>\n",
       "      <td>1008.117776</td>\n",
       "      <td>143.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.208663</td>\n",
       "      <td>372.874736</td>\n",
       "      <td>382.716000</td>\n",
       "      <td>2974.3700</td>\n",
       "      <td>2425.002856</td>\n",
       "      <td>1198.682000</td>\n",
       "      <td>1526.041689</td>\n",
       "      <td>1030.656401</td>\n",
       "      <td>466.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1102.839877</td>\n",
       "      <td>532.386000</td>\n",
       "      <td>7013.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>219.260</td>\n",
       "      <td>9658.6500</td>\n",
       "      <td>2219.842000</td>\n",
       "      <td>2224.166000</td>\n",
       "      <td>1901.7640</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1283.255000</td>\n",
       "      <td>1954.4460</td>\n",
       "      <td>5079.6200</td>\n",
       "      <td>3479.505000</td>\n",
       "      <td>183.500072</td>\n",
       "      <td>207.530000</td>\n",
       "      <td>3953.643222</td>\n",
       "      <td>3108.777354</td>\n",
       "      <td>171.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319.369422</td>\n",
       "      <td>470.183000</td>\n",
       "      <td>489.700000</td>\n",
       "      <td>3719.7230</td>\n",
       "      <td>3166.900000</td>\n",
       "      <td>1462.223000</td>\n",
       "      <td>2022.082864</td>\n",
       "      <td>1360.456000</td>\n",
       "      <td>569.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1443.946433</td>\n",
       "      <td>914.291722</td>\n",
       "      <td>9369.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>663.159</td>\n",
       "      <td>14517.6400</td>\n",
       "      <td>8530.666241</td>\n",
       "      <td>8678.166310</td>\n",
       "      <td>5895.1420</td>\n",
       "      <td>3944.342000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.97</th>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1494.030000</td>\n",
       "      <td>2550.3656</td>\n",
       "      <td>5806.0894</td>\n",
       "      <td>3756.449800</td>\n",
       "      <td>206.750000</td>\n",
       "      <td>277.349800</td>\n",
       "      <td>5344.317800</td>\n",
       "      <td>3848.737683</td>\n",
       "      <td>188.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>394.239829</td>\n",
       "      <td>518.460093</td>\n",
       "      <td>531.579909</td>\n",
       "      <td>3911.4698</td>\n",
       "      <td>3468.869800</td>\n",
       "      <td>1657.019000</td>\n",
       "      <td>2145.500000</td>\n",
       "      <td>1476.419800</td>\n",
       "      <td>594.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1554.880000</td>\n",
       "      <td>1212.859200</td>\n",
       "      <td>10491.98</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1438.158</td>\n",
       "      <td>16578.6164</td>\n",
       "      <td>8724.403682</td>\n",
       "      <td>8842.707361</td>\n",
       "      <td>7593.6286</td>\n",
       "      <td>5949.906800</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>74.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1646.890000</td>\n",
       "      <td>3041.7600</td>\n",
       "      <td>6191.2762</td>\n",
       "      <td>4060.309600</td>\n",
       "      <td>257.643200</td>\n",
       "      <td>311.470000</td>\n",
       "      <td>6729.450000</td>\n",
       "      <td>4875.056703</td>\n",
       "      <td>208.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>637.039800</td>\n",
       "      <td>836.146600</td>\n",
       "      <td>579.386600</td>\n",
       "      <td>4200.4596</td>\n",
       "      <td>3679.393200</td>\n",
       "      <td>1792.980000</td>\n",
       "      <td>2434.479800</td>\n",
       "      <td>1571.756600</td>\n",
       "      <td>639.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1601.910000</td>\n",
       "      <td>1317.506600</td>\n",
       "      <td>11367.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4289.780</td>\n",
       "      <td>18614.3528</td>\n",
       "      <td>254687.000000</td>\n",
       "      <td>254687.000000</td>\n",
       "      <td>8846.9728</td>\n",
       "      <td>7366.836600</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Number of Dependents      roam_ic    roam_og  loc_og_t2t  \\\n",
       "0.10  24.0                   0.0     0.000000     0.0000      0.0000   \n",
       "0.25  28.0                   0.0    12.080000    14.7000     32.6950   \n",
       "0.50  34.0                   0.0    50.560000    75.1000    171.3300   \n",
       "0.75  43.0                   1.0   162.060000   135.2900    309.0900   \n",
       "0.80  47.0                   2.0   496.940126   146.8200    856.8840   \n",
       "0.90  55.0                   4.0   969.100000   689.4660   3613.8880   \n",
       "0.95  61.0                   7.0  1283.255000  1954.4460   5079.6200   \n",
       "0.97  64.0                   8.0  1494.030000  2550.3656   5806.0894   \n",
       "0.99  74.0                   9.0  1646.890000  3041.7600   6191.2762   \n",
       "\n",
       "       loc_og_t2m  loc_og_t2f  loc_og_t2c   std_og_t2t   std_og_t2m  \\\n",
       "0.10     0.000000    0.000000    0.000000     0.000000     0.000000   \n",
       "0.25    26.260000    1.460000    1.610000    33.120000    25.550000   \n",
       "0.50   135.460000    7.800000    8.180000   174.610000   134.800000   \n",
       "0.75   618.310000   14.090000   14.700068   316.240000   244.510000   \n",
       "0.80  1393.012469   43.886016   15.970000   344.970000   266.550000   \n",
       "0.90  2644.684000  126.618596  109.120000  1547.248709  1008.117776   \n",
       "0.95  3479.505000  183.500072  207.530000  3953.643222  3108.777354   \n",
       "0.97  3756.449800  206.750000  277.349800  5344.317800  3848.737683   \n",
       "0.99  4060.309600  257.643200  311.470000  6729.450000  4875.056703   \n",
       "\n",
       "      std_og_t2f  std_og_t2c      isd_og      spl_og   og_others  loc_ic_t2t  \\\n",
       "0.10        0.00         0.0    0.000000    0.000000    0.000000     34.7400   \n",
       "0.25        1.19         0.0    3.250000    4.940000    3.430000     85.5650   \n",
       "0.50        6.34         0.0   17.190000   25.580000   17.830000    171.5000   \n",
       "0.75       36.64         0.0   31.140000   46.190000  106.790000   1259.2650   \n",
       "0.80       71.61         0.0   33.910000   50.240000  229.242068   1999.5880   \n",
       "0.90      143.14         0.0  113.208663  372.874736  382.716000   2974.3700   \n",
       "0.95      171.81         0.0  319.369422  470.183000  489.700000   3719.7230   \n",
       "0.97      188.88         0.0  394.239829  518.460093  531.579909   3911.4698   \n",
       "0.99      208.18         0.0  637.039800  836.146600  579.386600   4200.4596   \n",
       "\n",
       "       loc_ic_t2m   loc_ic_t2f   std_ic_t2t   std_ic_t2m  std_ic_t2f  \\\n",
       "0.10    33.790000    14.460000    16.950000    13.060000        5.03   \n",
       "0.25    84.170000    36.120000    42.460000    32.190000       12.46   \n",
       "0.50   168.390000    72.060000    84.470000    64.760000       24.98   \n",
       "0.75  1090.100000   496.805000   126.280000   448.831338      186.72   \n",
       "0.80  1471.763855   653.084534   543.225916   634.160224      275.20   \n",
       "0.90  2425.002856  1198.682000  1526.041689  1030.656401      466.85   \n",
       "0.95  3166.900000  1462.223000  2022.082864  1360.456000      569.74   \n",
       "0.97  3468.869800  1657.019000  2145.500000  1476.419800      594.01   \n",
       "0.99  3679.393200  1792.980000  2434.479800  1571.756600      639.00   \n",
       "\n",
       "      std_ic_t2o  spl_ic       isd_ic    ic_others  total_rech_amt  \\\n",
       "0.10         0.0    0.02    10.770000     8.100000            0.00   \n",
       "0.25         0.0    0.04    26.980000    20.330000           72.00   \n",
       "0.50         0.0    0.08    53.700000    40.540000          374.00   \n",
       "0.75         0.0    0.21    80.380000    60.730000         1089.00   \n",
       "0.80         0.0    0.33   384.901558    64.800000         2197.00   \n",
       "0.90         0.0    0.71  1102.839877   532.386000         7013.00   \n",
       "0.95         0.0    1.27  1443.946433   914.291722         9369.00   \n",
       "0.97         0.0    1.75  1554.880000  1212.859200        10491.98   \n",
       "0.99         0.0    2.19  1601.910000  1317.506600        11367.00   \n",
       "\n",
       "      total_rech_data    vol_4g      vol_5g        arpu_5g        arpu_4g  \\\n",
       "0.10              0.0     0.000      0.0000       0.000000       0.000000   \n",
       "0.25              0.0     0.000      0.0000       0.000000       0.000000   \n",
       "0.50              0.0    47.010    274.1400       0.000000       0.000000   \n",
       "0.75              2.0   154.910    895.8550     194.630000     228.400000   \n",
       "0.80              3.0   176.360   1655.2720     789.000000     783.452000   \n",
       "0.90             14.0   219.260   9658.6500    2219.842000    2224.166000   \n",
       "0.95             23.0   663.159  14517.6400    8530.666241    8678.166310   \n",
       "0.97             26.0  1438.158  16578.6164    8724.403682    8842.707361   \n",
       "0.99             30.0  4289.780  18614.3528  254687.000000  254687.000000   \n",
       "\n",
       "           arpu   aug_vbc_5g  Number of Referrals  Satisfaction Score  \\\n",
       "0.10  -256.2000     0.000000                  0.0                 1.0   \n",
       "0.25   118.9600     0.000000                  0.0                 3.0   \n",
       "0.50   348.5400   117.360000                  4.0                 3.0   \n",
       "0.75   580.6550   311.760000                  8.0                 4.0   \n",
       "0.80   626.2400   350.531298                  8.0                 4.0   \n",
       "0.90  1901.7640   789.000000                 10.0                 5.0   \n",
       "0.95  5895.1420  3944.342000                 11.0                 5.0   \n",
       "0.97  7593.6286  5949.906800                 11.0                 5.0   \n",
       "0.99  8846.9728  7366.836600                 11.0                 5.0   \n",
       "\n",
       "      Streaming Data Consumption  \n",
       "0.10                         0.0  \n",
       "0.25                         2.0  \n",
       "0.50                        20.0  \n",
       "0.75                        49.0  \n",
       "0.80                        56.0  \n",
       "0.90                        69.0  \n",
       "0.95                        77.0  \n",
       "0.97                        80.0  \n",
       "0.99                        83.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the quantiles df\n",
    "quantile_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqnLtZs1Z-2p"
   },
   "source": [
    "Outliers were detected in the variables vol_5g, arpu_4g, and arpu_5g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "U6NQZsd3Z-2q",
    "outputId": "38bb54e5-ed40-4a05-f29b-655ae1544e25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750       228.400000\n",
       "0.800       783.452000\n",
       "0.900      2224.166000\n",
       "0.950      8678.166310\n",
       "0.970      8842.707361\n",
       "0.990    254687.000000\n",
       "0.999    254687.000000\n",
       "Name: arpu_4g, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking further\n",
    "df['arpu_4g'].quantile([0.75,0.8,0.9,0.95,0.97,0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Bcx5-kVNZ-2q",
    "outputId": "025b06d2-46ae-45c2-e63b-40e810bb416e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01965765531384147"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the proportion of rows in the DataFrame where the value in the 'arpu_4g' column is equal to 254687\n",
    "df[df['arpu_4g']==254687].shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "YJjw0lS5Z-2q",
    "outputId": "1db27add-bcf1-4a9c-d84d-a1c77fd25f44"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Month of Joining</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Location ID</th>\n",
       "      <th>Service ID</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>timezone</th>\n",
       "      <th>area_codes</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>arpu</th>\n",
       "      <th>roam_ic</th>\n",
       "      <th>roam_og</th>\n",
       "      <th>loc_og_t2t</th>\n",
       "      <th>loc_og_t2m</th>\n",
       "      <th>loc_og_t2f</th>\n",
       "      <th>loc_og_t2c</th>\n",
       "      <th>std_og_t2t</th>\n",
       "      <th>std_og_t2m</th>\n",
       "      <th>std_og_t2f</th>\n",
       "      <th>std_og_t2c</th>\n",
       "      <th>isd_og</th>\n",
       "      <th>spl_og</th>\n",
       "      <th>og_others</th>\n",
       "      <th>loc_ic_t2t</th>\n",
       "      <th>loc_ic_t2m</th>\n",
       "      <th>loc_ic_t2f</th>\n",
       "      <th>std_ic_t2t</th>\n",
       "      <th>std_ic_t2m</th>\n",
       "      <th>std_ic_t2f</th>\n",
       "      <th>std_ic_t2o</th>\n",
       "      <th>spl_ic</th>\n",
       "      <th>isd_ic</th>\n",
       "      <th>ic_others</th>\n",
       "      <th>total_rech_amt</th>\n",
       "      <th>total_rech_data</th>\n",
       "      <th>vol_4g</th>\n",
       "      <th>vol_5g</th>\n",
       "      <th>arpu_5g</th>\n",
       "      <th>arpu_4g</th>\n",
       "      <th>aug_vbc_5g</th>\n",
       "      <th>Churn Value</th>\n",
       "      <th>Referred a Friend</th>\n",
       "      <th>Number of Referrals</th>\n",
       "      <th>Phone Service</th>\n",
       "      <th>Multiple Lines</th>\n",
       "      <th>Internet Service</th>\n",
       "      <th>Internet Type</th>\n",
       "      <th>Streaming Data Consumption</th>\n",
       "      <th>Online Security</th>\n",
       "      <th>Online Backup</th>\n",
       "      <th>Device Protection Plan</th>\n",
       "      <th>Premium Tech Support</th>\n",
       "      <th>Streaming TV</th>\n",
       "      <th>Streaming Movies</th>\n",
       "      <th>Streaming Music</th>\n",
       "      <th>Unlimited Data</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Status ID</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>offer</th>\n",
       "      <th>age_bucket</th>\n",
       "      <th>rank</th>\n",
       "      <th>total_recharge</th>\n",
       "      <th>rank_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>uqdtniwvxqzeu1</td>\n",
       "      <td>14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>72566</td>\n",
       "      <td>Male</td>\n",
       "      <td>36.459363</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>qcvetdmalnkw1</td>\n",
       "      <td>tkqnsqflrdatnqapsh1</td>\n",
       "      <td>AR</td>\n",
       "      <td>Izard County</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>870.0</td>\n",
       "      <td>US</td>\n",
       "      <td>36.22</td>\n",
       "      <td>-92.08</td>\n",
       "      <td>1330.04</td>\n",
       "      <td>1582.05</td>\n",
       "      <td>157.20</td>\n",
       "      <td>161.810000</td>\n",
       "      <td>1827.38</td>\n",
       "      <td>39.790000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1362.59</td>\n",
       "      <td>5267.31</td>\n",
       "      <td>171.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>390.32</td>\n",
       "      <td>24.940000</td>\n",
       "      <td>511.23</td>\n",
       "      <td>2128.610000</td>\n",
       "      <td>2896.11</td>\n",
       "      <td>54.41</td>\n",
       "      <td>100.540000</td>\n",
       "      <td>585.44</td>\n",
       "      <td>162.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>10.460000</td>\n",
       "      <td>1247.37</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>74</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>inebwpymzwpup39698</td>\n",
       "      <td>4</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>35-49</td>\n",
       "      <td>480205.5</td>\n",
       "      <td>255.0</td>\n",
       "      <td>608671.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ucpurmfkdlnwi18</td>\n",
       "      <td>13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>71747</td>\n",
       "      <td>Female</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rqiqguxisfoc18</td>\n",
       "      <td>dkupusivpzrazcfsdi18</td>\n",
       "      <td>AR</td>\n",
       "      <td>Union County</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>870.0</td>\n",
       "      <td>US</td>\n",
       "      <td>33.04</td>\n",
       "      <td>-92.18</td>\n",
       "      <td>160.07</td>\n",
       "      <td>18.63</td>\n",
       "      <td>31.29</td>\n",
       "      <td>2894.610900</td>\n",
       "      <td>834.78</td>\n",
       "      <td>209.170000</td>\n",
       "      <td>9.59</td>\n",
       "      <td>177.64</td>\n",
       "      <td>116.17</td>\n",
       "      <td>120.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.74</td>\n",
       "      <td>439.375628</td>\n",
       "      <td>100.81</td>\n",
       "      <td>156.270000</td>\n",
       "      <td>254.19</td>\n",
       "      <td>29.68</td>\n",
       "      <td>998.952008</td>\n",
       "      <td>24.13</td>\n",
       "      <td>12.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>795.286166</td>\n",
       "      <td>5.06</td>\n",
       "      <td>8462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>usfobpyxwqrkg27554</td>\n",
       "      <td>5</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>18-24</td>\n",
       "      <td>600175.5</td>\n",
       "      <td>8462.0</td>\n",
       "      <td>75599.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>sirifvlkipkel21</td>\n",
       "      <td>13</td>\n",
       "      <td>11.0</td>\n",
       "      <td>92865</td>\n",
       "      <td>Female</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jobplwgowgko21</td>\n",
       "      <td>zmuwwsnfbwxxdxzuvz21</td>\n",
       "      <td>CA</td>\n",
       "      <td>Orange County</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>714.0</td>\n",
       "      <td>US</td>\n",
       "      <td>33.83</td>\n",
       "      <td>-117.85</td>\n",
       "      <td>478.77</td>\n",
       "      <td>26.04</td>\n",
       "      <td>72.49</td>\n",
       "      <td>111.050000</td>\n",
       "      <td>1.87</td>\n",
       "      <td>6.890000</td>\n",
       "      <td>4.83</td>\n",
       "      <td>11.50</td>\n",
       "      <td>134.28</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.44</td>\n",
       "      <td>6.230000</td>\n",
       "      <td>2.70</td>\n",
       "      <td>171.280000</td>\n",
       "      <td>167.16</td>\n",
       "      <td>15.18</td>\n",
       "      <td>54.880000</td>\n",
       "      <td>64.06</td>\n",
       "      <td>31.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>41.910000</td>\n",
       "      <td>61.24</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>56</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>cullucfodcpbc24549</td>\n",
       "      <td>3</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>35-49</td>\n",
       "      <td>284189.5</td>\n",
       "      <td>417.0</td>\n",
       "      <td>524369.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>dnnrchjlmrylq24</td>\n",
       "      <td>14</td>\n",
       "      <td>9.0</td>\n",
       "      <td>91423</td>\n",
       "      <td>Female</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>vxainqiqplai24</td>\n",
       "      <td>liroqcvpdnrzdyolqw24</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>2.13e+17</td>\n",
       "      <td>US</td>\n",
       "      <td>34.14</td>\n",
       "      <td>-118.42</td>\n",
       "      <td>143.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>149.180000</td>\n",
       "      <td>2769.19</td>\n",
       "      <td>207.23</td>\n",
       "      <td>33.720000</td>\n",
       "      <td>331.07</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>51</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>qflywarsexbpg13676</td>\n",
       "      <td>4</td>\n",
       "      <td>G</td>\n",
       "      <td>35-49</td>\n",
       "      <td>480205.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>497565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>pltaycxycbhvo31</td>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>95126</td>\n",
       "      <td>Other</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sjmjgqjvhvth31</td>\n",
       "      <td>xbmtjtsvypinczxnhf31</td>\n",
       "      <td>CA</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>408.0</td>\n",
       "      <td>US</td>\n",
       "      <td>37.32</td>\n",
       "      <td>-121.91</td>\n",
       "      <td>95.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3210.570000</td>\n",
       "      <td>525.28</td>\n",
       "      <td>136.57</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>1.21</td>\n",
       "      <td>202.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>61.380000</td>\n",
       "      <td>52.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Cable</td>\n",
       "      <td>56</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>xayhhjriwxte83055</td>\n",
       "      <td>3</td>\n",
       "      <td>J</td>\n",
       "      <td>25-34</td>\n",
       "      <td>284189.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>524369.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652999</th>\n",
       "      <td>tphemcbndfpem162885</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>91604</td>\n",
       "      <td>Female</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9.0</td>\n",
       "      <td>psxavglkqzny162885</td>\n",
       "      <td>lepgdnuzszymxfxefi162885</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>213.0</td>\n",
       "      <td>US</td>\n",
       "      <td>34.13</td>\n",
       "      <td>-118.39</td>\n",
       "      <td>576.68</td>\n",
       "      <td>1555.64</td>\n",
       "      <td>148.54</td>\n",
       "      <td>286.060000</td>\n",
       "      <td>2640.98</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>15.25</td>\n",
       "      <td>177.76</td>\n",
       "      <td>80.32</td>\n",
       "      <td>182.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.39</td>\n",
       "      <td>29.010000</td>\n",
       "      <td>12.66</td>\n",
       "      <td>149.150000</td>\n",
       "      <td>254.42</td>\n",
       "      <td>34.55</td>\n",
       "      <td>70.130000</td>\n",
       "      <td>866.24</td>\n",
       "      <td>21.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8.530000</td>\n",
       "      <td>13.05</td>\n",
       "      <td>6036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Wallet Balance</td>\n",
       "      <td>unsgjstmbbczmsf47552</td>\n",
       "      <td>3</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>18-24</td>\n",
       "      <td>284189.5</td>\n",
       "      <td>6036.0</td>\n",
       "      <td>224935.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653051</th>\n",
       "      <td>umbrcxomoexlc162896</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94939</td>\n",
       "      <td>Female</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uuqthlwgdxrn162896</td>\n",
       "      <td>njhcqhdfkoqrazlxxo162896</td>\n",
       "      <td>CA</td>\n",
       "      <td>Marin County</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>415.0</td>\n",
       "      <td>US</td>\n",
       "      <td>37.93</td>\n",
       "      <td>-122.53</td>\n",
       "      <td>5007.56</td>\n",
       "      <td>75.85</td>\n",
       "      <td>144.05</td>\n",
       "      <td>271.200000</td>\n",
       "      <td>30.16</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>242.12</td>\n",
       "      <td>349.01</td>\n",
       "      <td>1073.75</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.40</td>\n",
       "      <td>24.610000</td>\n",
       "      <td>2.62</td>\n",
       "      <td>106.590000</td>\n",
       "      <td>145.29</td>\n",
       "      <td>86.85</td>\n",
       "      <td>83.010000</td>\n",
       "      <td>29.74</td>\n",
       "      <td>23.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>54.30</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>23</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>mospmxtxyzdy97920</td>\n",
       "      <td>1</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>50-64</td>\n",
       "      <td>52747.5</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>353280.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653105</th>\n",
       "      <td>dkjfuyorfdngv162907</td>\n",
       "      <td>13</td>\n",
       "      <td>11.0</td>\n",
       "      <td>87553</td>\n",
       "      <td>Male</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>huiasasztqyw162907</td>\n",
       "      <td>dscivazeqkwgxzggqx162907</td>\n",
       "      <td>NM</td>\n",
       "      <td>Taos County</td>\n",
       "      <td>America/Denver</td>\n",
       "      <td>505575.0</td>\n",
       "      <td>US</td>\n",
       "      <td>36.17</td>\n",
       "      <td>-105.69</td>\n",
       "      <td>585.54</td>\n",
       "      <td>27.80</td>\n",
       "      <td>81.79</td>\n",
       "      <td>156.780000</td>\n",
       "      <td>22.08</td>\n",
       "      <td>1.970000</td>\n",
       "      <td>16.43</td>\n",
       "      <td>121.46</td>\n",
       "      <td>424.02</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.42</td>\n",
       "      <td>73.170000</td>\n",
       "      <td>10.20</td>\n",
       "      <td>164.160000</td>\n",
       "      <td>55.41</td>\n",
       "      <td>16.81</td>\n",
       "      <td>97.510000</td>\n",
       "      <td>73.50</td>\n",
       "      <td>22.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>74.750000</td>\n",
       "      <td>870.14</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>rgvqptvqmqule47777</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>18-24</td>\n",
       "      <td>130189.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>191954.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653218</th>\n",
       "      <td>jqvmittclvgqd162934</td>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>98907</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uviytafwcahi162934</td>\n",
       "      <td>whncxdyflgkmlzguym162934</td>\n",
       "      <td>WA</td>\n",
       "      <td>Yakima County</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>509.0</td>\n",
       "      <td>US</td>\n",
       "      <td>46.59</td>\n",
       "      <td>-120.52</td>\n",
       "      <td>373.84</td>\n",
       "      <td>25.65</td>\n",
       "      <td>143.85</td>\n",
       "      <td>318.780000</td>\n",
       "      <td>416.37</td>\n",
       "      <td>12.540000</td>\n",
       "      <td>13.25</td>\n",
       "      <td>317.96</td>\n",
       "      <td>182.93</td>\n",
       "      <td>10.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>14.43</td>\n",
       "      <td>170.040000</td>\n",
       "      <td>38.57</td>\n",
       "      <td>80.97</td>\n",
       "      <td>59.360000</td>\n",
       "      <td>7.93</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>67.120000</td>\n",
       "      <td>13.64</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>14</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>qpzsyhumyefn64654</td>\n",
       "      <td>4</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>35-49</td>\n",
       "      <td>480205.5</td>\n",
       "      <td>244.0</td>\n",
       "      <td>268482.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653262</th>\n",
       "      <td>lvinoatdykyvc162940</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>98132</td>\n",
       "      <td>Male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mkumlrxlywbx162940</td>\n",
       "      <td>mumzhcmhaezoytzzxz162940</td>\n",
       "      <td>WA</td>\n",
       "      <td>King County</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>206.0</td>\n",
       "      <td>US</td>\n",
       "      <td>47.46</td>\n",
       "      <td>-122.29</td>\n",
       "      <td>-1375.56</td>\n",
       "      <td>721.64</td>\n",
       "      <td>108.51</td>\n",
       "      <td>1961.508811</td>\n",
       "      <td>3763.21</td>\n",
       "      <td>76.981985</td>\n",
       "      <td>277.63</td>\n",
       "      <td>321.61</td>\n",
       "      <td>3679.66</td>\n",
       "      <td>63.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.62</td>\n",
       "      <td>223.790501</td>\n",
       "      <td>339.71</td>\n",
       "      <td>1314.886171</td>\n",
       "      <td>2396.71</td>\n",
       "      <td>180.15</td>\n",
       "      <td>609.826087</td>\n",
       "      <td>371.14</td>\n",
       "      <td>72.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>456.927366</td>\n",
       "      <td>207.00</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254687.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>52</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Wallet Balance</td>\n",
       "      <td>npxyweakifbwm3141</td>\n",
       "      <td>5</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>25-34</td>\n",
       "      <td>600175.5</td>\n",
       "      <td>619.0</td>\n",
       "      <td>502475.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12845 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Customer ID  Month  Month of Joining  zip_code         Gender  \\\n",
       "9            uqdtniwvxqzeu1     14               6.0     72566           Male   \n",
       "86          ucpurmfkdlnwi18     13              12.0     71747         Female   \n",
       "103         sirifvlkipkel21     13              11.0     92865         Female   \n",
       "112         dnnrchjlmrylq24     14               9.0     91423         Female   \n",
       "145         pltaycxycbhvo31     11               7.0     95126          Other   \n",
       "...                     ...    ...               ...       ...            ...   \n",
       "652999  tphemcbndfpem162885      5               5.0     91604         Female   \n",
       "653051  umbrcxomoexlc162896      8               5.0     94939         Female   \n",
       "653105  dkjfuyorfdngv162907     13              11.0     87553           Male   \n",
       "653218  jqvmittclvgqd162934     11               7.0     98907  Not Specified   \n",
       "653262  lvinoatdykyvc162940      7               6.0     98132           Male   \n",
       "\n",
       "              Age        Married     Dependents  Number of Dependents  \\\n",
       "9       36.459363             No             No                   0.0   \n",
       "86      20.000000            Yes             No                   0.0   \n",
       "103     40.000000            Yes             No                   0.0   \n",
       "112     48.000000            Yes            Yes                   0.0   \n",
       "145     35.000000             No             No                   0.0   \n",
       "...           ...            ...            ...                   ...   \n",
       "652999  23.000000            Yes            Yes                   9.0   \n",
       "653051  55.000000            Yes  Not Specified                   0.0   \n",
       "653105  23.000000            Yes            Yes                   2.0   \n",
       "653218  40.000000            Yes             No                   0.0   \n",
       "653262  27.000000  Not Specified  Not Specified                   0.0   \n",
       "\n",
       "               Location ID                Service ID state  \\\n",
       "9            qcvetdmalnkw1       tkqnsqflrdatnqapsh1    AR   \n",
       "86          rqiqguxisfoc18      dkupusivpzrazcfsdi18    AR   \n",
       "103         jobplwgowgko21      zmuwwsnfbwxxdxzuvz21    CA   \n",
       "112         vxainqiqplai24      liroqcvpdnrzdyolqw24    CA   \n",
       "145         sjmjgqjvhvth31      xbmtjtsvypinczxnhf31    CA   \n",
       "...                    ...                       ...   ...   \n",
       "652999  psxavglkqzny162885  lepgdnuzszymxfxefi162885    CA   \n",
       "653051  uuqthlwgdxrn162896  njhcqhdfkoqrazlxxo162896    CA   \n",
       "653105  huiasasztqyw162907  dscivazeqkwgxzggqx162907    NM   \n",
       "653218  uviytafwcahi162934  whncxdyflgkmlzguym162934    WA   \n",
       "653262  mkumlrxlywbx162940  mumzhcmhaezoytzzxz162940    WA   \n",
       "\n",
       "                    county             timezone area_codes country  latitude  \\\n",
       "9             Izard County      America/Chicago      870.0      US     36.22   \n",
       "86            Union County      America/Chicago      870.0      US     33.04   \n",
       "103          Orange County  America/Los_Angeles      714.0      US     33.83   \n",
       "112     Los Angeles County  America/Los_Angeles   2.13e+17      US     34.14   \n",
       "145     Santa Clara County  America/Los_Angeles      408.0      US     37.32   \n",
       "...                    ...                  ...        ...     ...       ...   \n",
       "652999  Los Angeles County  America/Los_Angeles      213.0      US     34.13   \n",
       "653051        Marin County  America/Los_Angeles      415.0      US     37.93   \n",
       "653105         Taos County       America/Denver   505575.0      US     36.17   \n",
       "653218       Yakima County  America/Los_Angeles      509.0      US     46.59   \n",
       "653262         King County  America/Los_Angeles      206.0      US     47.46   \n",
       "\n",
       "        longitude     arpu  roam_ic  roam_og   loc_og_t2t  loc_og_t2m  \\\n",
       "9          -92.08  1330.04  1582.05   157.20   161.810000     1827.38   \n",
       "86         -92.18   160.07    18.63    31.29  2894.610900      834.78   \n",
       "103       -117.85   478.77    26.04    72.49   111.050000        1.87   \n",
       "112       -118.42   143.68     0.00     0.00     0.000000        0.00   \n",
       "145       -121.91    95.40     0.00     0.00     0.000000        0.00   \n",
       "...           ...      ...      ...      ...          ...         ...   \n",
       "652999    -118.39   576.68  1555.64   148.54   286.060000     2640.98   \n",
       "653051    -122.53  5007.56    75.85   144.05   271.200000       30.16   \n",
       "653105    -105.69   585.54    27.80    81.79   156.780000       22.08   \n",
       "653218    -120.52   373.84    25.65   143.85   318.780000      416.37   \n",
       "653262    -122.29 -1375.56   721.64   108.51  1961.508811     3763.21   \n",
       "\n",
       "        loc_og_t2f  loc_og_t2c  std_og_t2t  std_og_t2m  std_og_t2f  \\\n",
       "9        39.790000        1.00     1362.59     5267.31      171.81   \n",
       "86      209.170000        9.59      177.64      116.17      120.34   \n",
       "103       6.890000        4.83       11.50      134.28        6.71   \n",
       "112       0.000000        0.00        0.00        0.00        0.00   \n",
       "145       0.000000        0.00        0.00        0.00        0.00   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "652999   11.450000       15.25      177.76       80.32      182.42   \n",
       "653051   10.500000      242.12      349.01     1073.75        1.19   \n",
       "653105    1.970000       16.43      121.46      424.02        0.87   \n",
       "653218   12.540000       13.25      317.96      182.93       10.41   \n",
       "653262   76.981985      277.63      321.61     3679.66       63.09   \n",
       "\n",
       "        std_og_t2c  isd_og      spl_og  og_others   loc_ic_t2t  loc_ic_t2m  \\\n",
       "9              0.0  390.32   24.940000     511.23  2128.610000     2896.11   \n",
       "86             0.0   14.74  439.375628     100.81   156.270000      254.19   \n",
       "103            0.0   31.44    6.230000       2.70   171.280000      167.16   \n",
       "112            0.0    0.00    0.000000       0.00   149.180000     2769.19   \n",
       "145            0.0    0.00    0.000000       0.00  3210.570000      525.28   \n",
       "...            ...     ...         ...        ...          ...         ...   \n",
       "652999         0.0   36.39   29.010000      12.66   149.150000      254.42   \n",
       "653051         0.0   30.40   24.610000       2.62   106.590000      145.29   \n",
       "653105         0.0   19.42   73.170000      10.20   164.160000       55.41   \n",
       "653218         0.0   11.00   31.100000      14.43   170.040000       38.57   \n",
       "653262         0.0    4.62  223.790501     339.71  1314.886171     2396.71   \n",
       "\n",
       "        loc_ic_t2f  std_ic_t2t  std_ic_t2m  std_ic_t2f  std_ic_t2o  spl_ic  \\\n",
       "9            54.41  100.540000      585.44      162.70         0.0    0.11   \n",
       "86           29.68  998.952008       24.13       12.62         0.0    0.29   \n",
       "103          15.18   54.880000       64.06       31.83         0.0    0.01   \n",
       "112         207.23   33.720000      331.07        3.33         0.0    0.06   \n",
       "145         136.57   19.790000        1.21      202.92         0.0    0.05   \n",
       "...            ...         ...         ...         ...         ...     ...   \n",
       "652999       34.55   70.130000      866.24       21.63         0.0    0.02   \n",
       "653051       86.85   83.010000       29.74       23.25         0.0    0.06   \n",
       "653105       16.81   97.510000       73.50       22.02         0.0    0.10   \n",
       "653218       80.97   59.360000        7.93       12.83         0.0    0.03   \n",
       "653262      180.15  609.826087      371.14       72.47         0.0    0.03   \n",
       "\n",
       "            isd_ic  ic_others  total_rech_amt  total_rech_data  vol_4g  \\\n",
       "9        10.460000    1247.37           255.0              0.0     0.0   \n",
       "86      795.286166       5.06          8462.0              0.0     0.0   \n",
       "103      41.910000      61.24           417.0              0.0     0.0   \n",
       "112       0.090000       2.56             0.0              0.0     0.0   \n",
       "145      61.380000      52.97             0.0              0.0     0.0   \n",
       "...            ...        ...             ...              ...     ...   \n",
       "652999    8.530000      13.05          6036.0              0.0     0.0   \n",
       "653051   61.500000      54.30          1518.0              0.0     0.0   \n",
       "653105   74.750000     870.14           229.0              0.0     0.0   \n",
       "653218   67.120000      13.64           244.0              0.0     0.0   \n",
       "653262  456.927366     207.00           619.0              0.0     0.0   \n",
       "\n",
       "        vol_5g   arpu_5g   arpu_4g  aug_vbc_5g  Churn Value Referred a Friend  \\\n",
       "9          0.0  254687.0  254687.0         0.0            0               Yes   \n",
       "86         0.0       0.0  254687.0         0.0            0               Yes   \n",
       "103        0.0       0.0  254687.0         0.0            0               Yes   \n",
       "112        0.0       0.0  254687.0         0.0            0               Yes   \n",
       "145        0.0       0.0  254687.0         0.0            0               Yes   \n",
       "...        ...       ...       ...         ...          ...               ...   \n",
       "652999     0.0       0.0  254687.0        63.0            0               Yes   \n",
       "653051     0.0       0.0  254687.0         0.0            0               Yes   \n",
       "653105     0.0       0.0  254687.0         0.0            1               Yes   \n",
       "653218     0.0       0.0  254687.0         0.0            0                No   \n",
       "653262     0.0       0.0  254687.0         0.0            0                No   \n",
       "\n",
       "        Number of Referrals Phone Service Multiple Lines Internet Service  \\\n",
       "9                       9.0           Yes             No               No   \n",
       "86                      6.0           Yes            Yes               No   \n",
       "103                     0.0           Yes            Yes               No   \n",
       "112                     6.0            No            Yes               No   \n",
       "145                    10.0            No             No               No   \n",
       "...                     ...           ...            ...              ...   \n",
       "652999                  7.0           Yes             No               No   \n",
       "653051                  8.0           Yes            Yes               No   \n",
       "653105                  9.0           Yes             No               No   \n",
       "653218                  0.0           Yes            Yes               No   \n",
       "653262                  3.0           Yes             No               No   \n",
       "\n",
       "         Internet Type  Streaming Data Consumption Online Security  \\\n",
       "9       Not Applicable                          74              No   \n",
       "86      Not Applicable                           0              No   \n",
       "103     Not Applicable                          56              No   \n",
       "112     Not Applicable                          51              No   \n",
       "145              Cable                          56              No   \n",
       "...                ...                         ...             ...   \n",
       "652999  Not Applicable                           8              No   \n",
       "653051  Not Applicable                          23              No   \n",
       "653105  Not Applicable                           4              No   \n",
       "653218  Not Applicable                          14              No   \n",
       "653262     Fiber Optic                          52              No   \n",
       "\n",
       "       Online Backup Device Protection Plan Premium Tech Support Streaming TV  \\\n",
       "9                 No                    Yes                   No          Yes   \n",
       "86                No                     No                  Yes           No   \n",
       "103              Yes                    Yes                   No          Yes   \n",
       "112              Yes                    Yes                   No           No   \n",
       "145              Yes                     No                   No           No   \n",
       "...              ...                    ...                  ...          ...   \n",
       "652999            No                     No                   No          Yes   \n",
       "653051            No                    Yes                   No          Yes   \n",
       "653105            No                     No                   No          Yes   \n",
       "653218           Yes                    Yes                   No          Yes   \n",
       "653262           Yes                     No                  Yes          Yes   \n",
       "\n",
       "       Streaming Movies Streaming Music Unlimited Data   Payment Method  \\\n",
       "9                    No              No             No      Credit Card   \n",
       "86                   No              No             No  Bank Withdrawal   \n",
       "103                 Yes             Yes             No      Credit Card   \n",
       "112                 Yes             Yes             No  Bank Withdrawal   \n",
       "145                 Yes             Yes             No  Bank Withdrawal   \n",
       "...                 ...             ...            ...              ...   \n",
       "652999               No              No             No   Wallet Balance   \n",
       "653051              Yes             Yes             No      Credit Card   \n",
       "653105               No              No             No  Bank Withdrawal   \n",
       "653218               No              No             No  Bank Withdrawal   \n",
       "653262              Yes             Yes             No   Wallet Balance   \n",
       "\n",
       "                   Status ID  Satisfaction Score     offer age_bucket  \\\n",
       "9         inebwpymzwpup39698                   4  No Offer      35-49   \n",
       "86        usfobpyxwqrkg27554                   5  No Offer      18-24   \n",
       "103       cullucfodcpbc24549                   3  No Offer      35-49   \n",
       "112       qflywarsexbpg13676                   4         G      35-49   \n",
       "145        xayhhjriwxte83055                   3         J      25-34   \n",
       "...                      ...                 ...       ...        ...   \n",
       "652999  unsgjstmbbczmsf47552                   3  No Offer      18-24   \n",
       "653051     mospmxtxyzdy97920                   1  No Offer      50-64   \n",
       "653105    rgvqptvqmqule47777                   2         D      18-24   \n",
       "653218     qpzsyhumyefn64654                   4  No Offer      35-49   \n",
       "653262     npxyweakifbwm3141                   5  No Offer      25-34   \n",
       "\n",
       "            rank  total_recharge    rank_x  \n",
       "9       480205.5           255.0  608671.5  \n",
       "86      600175.5          8462.0   75599.5  \n",
       "103     284189.5           417.0  524369.5  \n",
       "112     480205.5             0.0  497565.0  \n",
       "145     284189.5             0.0  524369.5  \n",
       "...          ...             ...       ...  \n",
       "652999  284189.5          6036.0  224935.5  \n",
       "653051   52747.5          1518.0  353280.5  \n",
       "653105  130189.0           229.0  191954.5  \n",
       "653218  480205.5           244.0  268482.5  \n",
       "653262  600175.5           619.0  502475.5  \n",
       "\n",
       "[12845 rows x 73 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check it out\n",
    "df[df['arpu_4g']==254687]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzzuy2bvZ-2q"
   },
   "source": [
    "Let's see what is the value of 'total_rech_data' for these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "GJ8kQmwSZ-2q",
    "outputId": "d3a243b3-42d2-493b-bb96-56205bcb39b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rech_data\n",
       "0.0    12845\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the value counts of 'total_rech_data' for observations where the value in the 'arpu_4g' column is equal to 254687\n",
    "df[df['arpu_4g']==254687]['total_rech_data'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4c454tIZ-2q"
   },
   "source": [
    "Now, since the recharge amount is 0 and there is no ARPU, let's replace it with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "akCqNl15Z-2q"
   },
   "outputs": [],
   "source": [
    "# Replace the outlier value 254687 in the 'arpu_4g' column of the dataframe 'df' with 0.\n",
    "df['arpu_4g']=df['arpu_4g'].replace(254687,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "s2m3EgcRZ-2q",
    "outputId": "3204f340-6a72-487b-9858-e5f427e386a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750      120.600000\n",
       "0.800      504.194000\n",
       "0.900     1893.872000\n",
       "0.950     2493.923000\n",
       "0.970     8678.332415\n",
       "0.990     8842.707361\n",
       "0.999    87978.000000\n",
       "Name: arpu_4g, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking further\n",
    "df['arpu_4g'].quantile([0.75,0.8,0.9,0.95,0.97,0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Crbcd8PaZ-2q",
    "outputId": "46ab4a55-fca0-4856-b020-4aae00dd8f39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rech_data\n",
       "0.0    5006\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter by 'arpu_4g' value of 87978 and count unique values in 'total_rech_data' column\n",
    "df[df['arpu_4g']==87978]['total_rech_data'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9jocWPh15J1"
   },
   "source": [
    "All rows in the dataframe with an 'arpu_4g' value of 87978 have 0 value in the 'total_rech_data' column, indicating that these are likely outliers. Therefore, we have decided to replace the 'arpu_4g' value for these rows with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "JuOjiovGZ-2q"
   },
   "outputs": [],
   "source": [
    "# Replace the values with 0\n",
    "df['arpu_4g']=df['arpu_4g'].replace(87978,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "I7aizZWaZ-2q",
    "outputId": "df37019b-2fd1-4893-c1e0-90fe814f778e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750     107.780000\n",
       "0.800     432.330000\n",
       "0.900    1803.678000\n",
       "0.950    2424.093000\n",
       "0.970    2735.677800\n",
       "0.990    8708.088152\n",
       "0.999    8842.707361\n",
       "Name: arpu_4g, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the quantiles again\n",
    "df['arpu_4g'].quantile([0.75,0.8,0.9,0.95,0.97,0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "dJp0H0BRZ-2r",
    "outputId": "c8944f7e-bad5-4350-d31c-1865a16518ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn Value\n",
       "0    16155\n",
       "1      980\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the churn value for this ARPU\n",
    "df[df['arpu_4g']>8000]['Churn Value'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrZP-iq5Z-2r"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    " * A higher ARPU suggests that a business is generating more revenue per user, which can be a positive sign for the business's profitability. However, a high ARPU can also imply churn, or the rate at which customers are leaving the business.\n",
    "\n",
    "* There are a few reasons why a high ARPU may imply churn. First, if a business is charging a high price for its services, it may attract a customer base that is more price-sensitive and likely to switch to a competitor if they find a better deal. This could result in a higher churn rate for the business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "bwB9svs2Z-2r",
    "outputId": "b3a34dfc-1ab0-45bd-e2a8-309ce4410416"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rech_data\n",
       "0.0    12608\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value counts of total recharge data at outlying values\n",
    "df[df['arpu_5g']==254687]['total_rech_data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "HvnOLN9tZ-2r",
    "outputId": "90a82a8b-493d-4aa9-e99d-9ba7a700cf3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rech_data\n",
       "0.0    5126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value counts of total recharge data at outlying values\n",
    "df[df['arpu_5g']==87978]['total_rech_data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "wWUCA-0QZ-2r"
   },
   "outputs": [],
   "source": [
    "# Replacing the values with 0 where total recharge data is 0\n",
    "df['arpu_5g']=df['arpu_5g'].replace([87978,254687],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "eZ2G0_CgZ-2r",
    "outputId": "b3a9fe9c-cd7b-4380-8382-f24202b15506"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750      96.525000\n",
       "0.800     417.224000\n",
       "0.900    1797.658000\n",
       "0.950    2543.916000\n",
       "0.970    2792.089400\n",
       "0.990    8587.032306\n",
       "0.999    8724.403682\n",
       "Name: arpu_5g, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the quantiles of ARPU 5G\n",
    "df['arpu_5g'].quantile([0.75,0.8,0.9,0.95,0.97,0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "288nXt4mZ-2r",
    "outputId": "f8c7d42f-d79d-4a2e-ce81-241662b06e73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750      895.8550\n",
       "0.800     1655.2720\n",
       "0.900     9658.6500\n",
       "0.950    14517.6400\n",
       "0.970    16578.6164\n",
       "0.980    17550.9976\n",
       "0.990    18614.3528\n",
       "0.999    19746.1266\n",
       "Name: vol_5g, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the quantiles of Volume of 5G data\n",
    "df['vol_5g'].quantile([0.75,0.8,0.9,0.95,0.97,0.98,0.99,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "jk5WDhO4Z-2r",
    "outputId": "966f2b53-c1e2-4e62-b4ca-93f6e36514da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see the recharge data value\n",
    "df[df['vol_5g']>=87978]['total_rech_data'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "BnX_gEMTZ-2r",
    "outputId": "8a09bdf3-d41b-433e-9526-a9b4bdbe13d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of these values\n",
    "df[df['vol_5g']>=87978]['total_rech_data'].value_counts()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GufyTVuZ-2s"
   },
   "source": [
    "**Observation**:\n",
    "\n",
    "There is a presence of 2% outliers in vol 5g, where the values are very high, but their total recharge data is 0. We will fill these outliers with 0, and below are some possible reasons why this could be:\n",
    "\n",
    "* Data recording error: It is possible that there was an error in recording the recharge data for these outliers, leading to an incorrect value of 0. In this case, it would make sense to fill the outliers with 0, as this is likely the correct value.\n",
    "\n",
    "* Promotions or bonuses: Another possibility is that these customers received promotions or bonuses that allowed them to use the service without recharging, leading to a total recharge data of 0. However, these customers may still be using the service heavily, leading to the high values in vol 5g. In this case, filling the outliers with 0 would make sense as it accurately reflects the lack of recharge data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "gnSUoP5cZ-2s"
   },
   "outputs": [],
   "source": [
    "# Replace the outlier values\n",
    "df['vol_5g']=df['vol_5g'].replace([87978,254687],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Yc4VgnXjZ-2s",
    "outputId": "d31adc30-66e5-4ba9-e5b9-c8e00886eb66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  6,  7,  8,  9, 10, 11, 12, 13, 14,  2,  3,  4,  5],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique months\n",
    "df['Month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "vyuox--FZ-2s",
    "outputId": "f46f2627-7512-4313-f160-ee23d12b5b19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  6., 11.,  9.,  8.,  7., 10.,  2., 12.,  3.,  5.,  4.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique months of joining\n",
    "df['Month of Joining'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiZ5l8yUZ-2s"
   },
   "source": [
    "We will get 4 quarters in month of joining!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "u-iiHq7o15J3"
   },
   "outputs": [],
   "source": [
    "# # Save Processed data\n",
    "# df.to_csv('../data/processed/processed_churn_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CY0wR2W15J3"
   },
   "source": [
    "### Quarterly Churn Analysis\n",
    "\n",
    "Quarterly churn analysis involves assessing customer attrition over a three-month period. This involves calculating the churn rate, which is the percentage of customers discontinuing service in a quarter.\n",
    "\n",
    "- **Timeliness**: Performing this analysis quarterly aids in timely evaluation of customer retention and churn. Regular assessment helps spot behavioral changes in customers, enabling prompt action.\n",
    "\n",
    "- **Strategy Evaluation**: Quarterly analysis helps gauge the success of customer retention strategies. An increase in churn rate prompts a review of past strategies, guiding future improvements.\n",
    "\n",
    "- **Financial Impact**: Churn significantly affects business finances. Quarterly analysis identifies revenue loss areas, aiding in taking preventive measures for financial stability and growth.\n",
    "\n",
    "- **Customer Insights**: This analysis yields insights into customer behavior and preferences. Understanding reasons behind churn can reveal patterns, aiding in service improvement and future retention.\n",
    "\n",
    "- **Benchmarking**: Quarterly churn analysis helps in benchmarking against industry standards and competitors, highlighting strengths and areas needing improvement for competitive edge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "bixkWnVAZ-2s"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to map a month to its corresponding quarter\n",
    "def map_month_to_quarter(month):\n",
    "    if math.isnan(month): # Handle NaN values if present\n",
    "        return None\n",
    "    quarter = math.ceil(month / 3)\n",
    "    return quarter\n",
    "\n",
    "# Insert a new column called 'Quarter of Joining' in the DataFrame 'df' and populate it with the quarter corresponding to the 'Month of Joining' column\n",
    "df.insert(loc=1,column='Quarter of Joining',value=df['Month of Joining'].apply(lambda x: map_month_to_quarter(x)))\n",
    "\n",
    "# Insert a new column called 'Quarter' in the DataFrame 'df'and populate it with the quarter corresponding to the 'Month' column\n",
    "df.insert(loc=1,column='Quarter',value= df['Month'].apply(lambda x: map_month_to_quarter(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "AwJBQcGLZ-2t"
   },
   "outputs": [],
   "source": [
    "# Remove duplicate rows in the DataFrame 'df' based on the 'Customer ID', 'Quarter', and 'Quarter of Joining' columns and keep only the last occurrence of each set of duplicates\n",
    "telco=df.drop_duplicates(subset=['Customer ID','Quarter','Quarter of Joining'],keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8GvS05j15J3"
   },
   "source": [
    "The 'train_data' DataFrame contains the data of customers who joined in the first quarter and were active in the first quarter. This dataset is used for training the churn prediction model.\n",
    "\n",
    "The 'test_data' DataFrame contains the data of customers who joined in the first quarter and were active in the second quarter. This dataset is used for testing the accuracy of the churn prediction model.\n",
    "\n",
    "The 'prediction_data' DataFrame contains the data of customers who joined in the second quarter and were active in the second quarter. This dataset is used for predicting the churn of customers who joined in the second quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "e-lrocBCZ-2t"
   },
   "outputs": [],
   "source": [
    "# Filter 1 and 2 quarter wise data\n",
    "train_data=telco[(telco['Quarter of Joining']==1)&(telco['Quarter']==1)]\n",
    "test_data=telco[(telco['Quarter of Joining']==1)&(telco['Quarter']==2)]\n",
    "prediction_data=telco[(telco['Quarter of Joining']==2)&(telco['Quarter']==2)]\n",
    "save_point(\"fcTel2\")\n",
    "#note that we have not used alot of data which we will use for feedback loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8RVRmNxZ-2t"
   },
   "source": [
    "### **Data Preprocessing**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "8O8pPwBlZ-2t",
    "outputId": "9ae89c5f-53fc-4df1-facf-b46eeede3f9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quarter  Quarter of Joining\n",
       "3        3                     30901\n",
       "4        3                     29111\n",
       "5        3                     26086\n",
       "2        2                     25618\n",
       "1        1                     24309\n",
       "3        2                     23514\n",
       "4        2                     21476\n",
       "5        2                     19200\n",
       "4        4                     17359\n",
       "2        1                     16706\n",
       "5        4                     16048\n",
       "3        1                     13724\n",
       "4        1                     12299\n",
       "5        1                     10944\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique counts of quarter and month of joining\n",
    "telco[['Quarter','Quarter of Joining']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "2U_wBCfdZ-2t",
    "outputId": "c9e19662-78b2-41c4-c950-852bc3acef6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24309, 75), (16706, 75))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the data\n",
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "JeGRNSUDZ-2t",
    "outputId": "0d902fb8-33e8-49eb-f0cb-7f5086b7f0f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn Value\n",
       "0    0.687235\n",
       "1    0.312765\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing value counts and checking the churn rate in 1st quarter or the training data\n",
    "train_data['Churn Value'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "Pn1taM8KZ-2t",
    "outputId": "34dbb65c-ae76-42e3-d1d2-9f588feab3bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer ID', 'Quarter', 'Quarter of Joining', 'Month',\n",
       "       'Month of Joining', 'zip_code', 'Gender', 'Age', 'Married',\n",
       "       'Dependents', 'Number of Dependents', 'Location ID', 'Service ID',\n",
       "       'state', 'county', 'timezone', 'area_codes', 'country', 'latitude',\n",
       "       'longitude', 'arpu', 'roam_ic', 'roam_og', 'loc_og_t2t', 'loc_og_t2m',\n",
       "       'loc_og_t2f', 'loc_og_t2c', 'std_og_t2t', 'std_og_t2m', 'std_og_t2f',\n",
       "       'std_og_t2c', 'isd_og', 'spl_og', 'og_others', 'loc_ic_t2t',\n",
       "       'loc_ic_t2m', 'loc_ic_t2f', 'std_ic_t2t', 'std_ic_t2m', 'std_ic_t2f',\n",
       "       'std_ic_t2o', 'spl_ic', 'isd_ic', 'ic_others', 'total_rech_amt',\n",
       "       'total_rech_data', 'vol_4g', 'vol_5g', 'arpu_5g', 'arpu_4g',\n",
       "       'aug_vbc_5g', 'Churn Value', 'Referred a Friend', 'Number of Referrals',\n",
       "       'Phone Service', 'Multiple Lines', 'Internet Service', 'Internet Type',\n",
       "       'Streaming Data Consumption', 'Online Security', 'Online Backup',\n",
       "       'Device Protection Plan', 'Premium Tech Support', 'Streaming TV',\n",
       "       'Streaming Movies', 'Streaming Music', 'Unlimited Data',\n",
       "       'Payment Method', 'Status ID', 'Satisfaction Score', 'offer',\n",
       "       'age_bucket', 'rank', 'total_recharge', 'rank_x'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns in Train data\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "xSt8tvLCZ-2t"
   },
   "outputs": [],
   "source": [
    "# Let's drop unnecessary columns\n",
    "drop_cols=['Customer ID', 'Quarter', 'Quarter of Joining', 'Month',\n",
    "       'Month of Joining', 'zip_code','Location ID', 'Service ID',\n",
    "       'state', 'county', 'timezone', 'area_codes', 'country', 'latitude',\n",
    "       'longitude','Status ID','age_bucket']\n",
    "\n",
    "train_data=train_data.drop(columns=drop_cols)\n",
    "test_data=test_data.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "4s2wqOZOZ-2t",
    "outputId": "45e7cbb7-459f-44d7-9735-34ebb8e13e45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Age', 'Married', 'Dependents', 'Number of Dependents',\n",
       "       'arpu', 'roam_ic', 'roam_og', 'loc_og_t2t', 'loc_og_t2m', 'loc_og_t2f',\n",
       "       'loc_og_t2c', 'std_og_t2t', 'std_og_t2m', 'std_og_t2f', 'std_og_t2c',\n",
       "       'isd_og', 'spl_og', 'og_others', 'loc_ic_t2t', 'loc_ic_t2m',\n",
       "       'loc_ic_t2f', 'std_ic_t2t', 'std_ic_t2m', 'std_ic_t2f', 'std_ic_t2o',\n",
       "       'spl_ic', 'isd_ic', 'ic_others', 'total_rech_amt', 'total_rech_data',\n",
       "       'vol_4g', 'vol_5g', 'arpu_5g', 'arpu_4g', 'aug_vbc_5g', 'Churn Value',\n",
       "       'Referred a Friend', 'Number of Referrals', 'Phone Service',\n",
       "       'Multiple Lines', 'Internet Service', 'Internet Type',\n",
       "       'Streaming Data Consumption', 'Online Security', 'Online Backup',\n",
       "       'Device Protection Plan', 'Premium Tech Support', 'Streaming TV',\n",
       "       'Streaming Movies', 'Streaming Music', 'Unlimited Data',\n",
       "       'Payment Method', 'Satisfaction Score', 'offer', 'rank',\n",
       "       'total_recharge', 'rank_x'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "OiHvfZ-aZ-2u"
   },
   "outputs": [],
   "source": [
    "# Splitting the train data into features and label\n",
    "X_train=train_data.drop(\"Churn Value\", axis = 1)\n",
    "y_train=train_data['Churn Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "tV0KZAHSZ-2u"
   },
   "outputs": [],
   "source": [
    "# Splitting the test data into features and label\n",
    "X_test=test_data.drop(\"Churn Value\", axis = 1)\n",
    "y_test=test_data['Churn Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "eWI8OHHwZ-2u",
    "outputId": "dc0b50fa-837b-4e11-e599-52e352b712e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31276481961413466, 0.17849874296659882)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % churn value\n",
    "y_train.mean(),y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "l7sLu8xVZ-2u"
   },
   "outputs": [],
   "source": [
    "#fit encoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "# train\n",
    "encoder.fit(X_train[categorical_cols])\n",
    "encoded_features = list(encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "X_train[encoded_features] = encoder.transform(X_train[categorical_cols])\n",
    "# test\n",
    "X_test[encoded_features] = encoder.transform(X_test[categorical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLyqWrSX15J5"
   },
   "source": [
    "##### **Note**\n",
    "\n",
    "We fit the encoder on the training set, but only transform the test set. This ensures that only the categories found in the training set are one hot encoded (which prevents **data leakage** - when information outside the training set is used to build the model). \n",
    "\n",
    "By encoding the labels all at once before dividing, we would be indirectly indicating that we already know what are the possible classes or numeric ranges we are going to see in the future. Depending on the definition, this could be defined as data leaking, because you can deduce information that isn't in the training set.\n",
    "\n",
    "We will use fit and transform on the training set and just transform on the test set which essentially means that the one hot encoder object is trained or fitted by seeing the values of just the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "ouPOkzzUZ-2u",
    "outputId": "7830e5db-25d6-40e6-a1ea-6b1686bcc187"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24309, 111)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "5oLmG73vZ-2u"
   },
   "outputs": [],
   "source": [
    "# drop original features\n",
    "X_train=X_train.drop(categorical_cols,axis=1)\n",
    "X_test=X_test.drop(categorical_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "iH1IbeEGZ-2u",
    "outputId": "54444f85-c9dd-4c0a-8b72-f69f65db130a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24309, 93)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check again\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "qZ3r_X7gZ-2v"
   },
   "outputs": [],
   "source": [
    "# Instantiate scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale Separate Columns\n",
    "# train\n",
    "X_train[cts_cols]  = scaler.fit_transform(X_train[cts_cols]) \n",
    "# test\n",
    "X_test[cts_cols]  = scaler.transform(X_test[cts_cols])\n",
    "preserve(\"fcTel2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "N_S5Rq7RZ-2v"
   },
   "outputs": [],
   "source": [
    "# Dump the scaler to use in transforming test data\n",
    "# dump(scaler, open('../data/output/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWNGtUnFO9Xb"
   },
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjAY-cCpPi_S"
   },
   "source": [
    "### **Supervised Machine Learning**\n",
    "\n",
    "Supervised learning is a type of machine learning where the algorithm learns from labeled data. In other words, the data used to train the algorithm includes input variables and corresponding output variables. The algorithm learns to predict the output variable based on the input variables. Supervised learning can be further divided into two categories: regression and classification.\n",
    "\n",
    "* **Regression** is a type of supervised learning where the algorithm learns to predict a continuous output variable. In other words, the output variable is a numerical value. Examples of regression problems include predicting housing prices, stock prices, or the amount of rainfall in a particular area.\n",
    "\n",
    "* **Classification**, on the other hand, is a type of supervised learning where the algorithm learns to predict a discrete output variable. In other words, the output variable is a category or label. Examples of classification problems include predicting whether an email is spam or not, whether a tumor is malignant or benign, or whether a customer is likely to churn or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_z-jF_g9QPWu"
   },
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Logistic regression is a machine learning algorithm used for binary classification tasks, such as predicting whether a customer will churn. It operates by examining the relationship between input variables (like customer demographics and usage) and a binary output (churn or not).\n",
    "\n",
    "Key points about Logistic Regression:\n",
    "\n",
    "- **Functioning**: It estimates the probability of an event (output variable) using a logistic function, which provides a value between 0 and 1.\n",
    "\n",
    "- **Nature of Algorithm**: Despite the name, logistic regression is used for classification. It gets its name from employing a logistic function to model probability.\n",
    "\n",
    "- **Regression to Classification**: The logistic function transforms the linear regression equation's output into a probability (between 0 and 1), enabling classification.\n",
    "\n",
    "- **Logistic Function**: Defined as $$\\text{sigmoid}(z) = \\frac{1}{1 + e^{-z}}$$, where \\( z \\) is a linear combination of input variables and weights.\n",
    "\n",
    "- **Probability Prediction**: The probability of the binary outcome is given by $$P(y=1|x) = \\text{sigmoid}(z)$$, with \\( y \\) as the binary outcome and \\( x \\) the input variables.\n",
    "\n",
    "- **Training the Model**: Involves minimizing the cross-entropy loss function, using labeled examples and an optimization algorithm like gradient descent.\n",
    "\n",
    "- **Cross-Entropy Loss**: Defined as $$L(y,\\hat{y}) = -\\frac{1}{N} \\sum y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)$$, with \\( y \\) being the binary outcome and \\( \\hat{y} \\) the predicted probability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ojrZMI6XO8O"
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "### Decision Trees in Classification\n",
    "\n",
    "Decision trees are a supervised learning algorithm suitable for both classification and regression tasks. Known for their interpretability and ability to handle various data types, they model target variables using simple decision rules from data features.\n",
    "\n",
    "- **Structure**: Begins with a root node representing the entire dataset, splitting into child nodes based on feature values. This recursive process creates a tree-like structure of decisions.\n",
    "  \n",
    "- **Nodes and Leaves**: Each node tests a feature, with branches as possible outcomes. Leaves represent final decisions or class labels.\n",
    "\n",
    "### Splitting Criteria\n",
    "\n",
    "The criterion for splitting at each node varies based on data and problem nature. Common criteria include:\n",
    "\n",
    "- **Gini Index**: Calculates the probability of misclassifying an element, aiming to minimize errors.\n",
    "- **Information Gain**: Assesses entropy reduction post-split, seeking to maximize information gain.\n",
    "- **Chi-Square**: Compares observed and expected class frequencies, minimizing distribution deviation.\n",
    "\n",
    "### Overfitting in Decision Trees\n",
    "\n",
    "Overfitting, where trees fit too closely to training data, is a key challenge. It's addressed by:\n",
    "\n",
    "- **Pruning**: Reducing tree complexity.\n",
    "- **Limiting Depth**: Restricting tree growth.\n",
    "- **Ensemble Methods**: Improving performance and reducing overfitting.\n",
    "\n",
    "### Ensemble Methods\n",
    "\n",
    "These methods combine multiple models for enhanced results:\n",
    "\n",
    "- **Bagging**: Trains multiple trees on data subsets, then aggregates predictions.\n",
    "- **Boosting**: Sequentially trains trees, each focusing on previous misclassifications, enhancing accuracy.\n",
    "\n",
    "In summary, decision trees are a robust tool for classification, offering clear decision-making insights. Performance hinges on the choice of splitting, stopping criteria, and whether ensemble methods are employed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ut9Sa3NrZWqi"
   },
   "source": [
    "### Random Forest\n",
    "\n",
    "Random Forest is an ensemble algorithm known for its high performance and ability to prevent overfitting. It operates by building numerous decision trees on varied data subsets and then aggregating their predictions.\n",
    "\n",
    "**Algorithm of Random Forest**\n",
    "\n",
    "The Random Forest algorithm involves these steps:\n",
    "\n",
    "- **Bootstrap Sampling**: Randomly select a subset of the training data with replacement, called a bootstrap sample.\n",
    "- **Feature Selection**: Randomly choose a subset of features.\n",
    "- **Tree Building**: Construct a decision tree with the bootstrap sample and selected features, choosing the best feature at each node.\n",
    "- **Repeat Process**: Build multiple trees following the above steps.\n",
    "- **Final Prediction**: For classification, take a majority vote from all trees; for regression, average their predictions.\n",
    "\n",
    "**Mathematics Behind Random Forest**\n",
    "\n",
    "Key mathematical concepts in Random Forest include:\n",
    "\n",
    "- **Decision Trees**: Recursive binary partitioning to split data, maximizing information gain at each node.\n",
    "- **Bootstrap Sampling**: Random sampling with replacement to create diverse data subsets, reducing overfitting.\n",
    "\n",
    "**Difference between Bagging and Random Forest**\n",
    "\n",
    "While both are ensemble methods using bootstrap sampling, they differ in:\n",
    "\n",
    "- **Feature Handling**: Bagging uses the same features for all models, potentially leading to correlated predictions. Random Forest selects random feature subsets, reducing prediction correlation and enhancing performance, particularly with high-dimensional data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F27Y1y-YbNJA"
   },
   "source": [
    "### Boosting\n",
    "\n",
    "Boosting is an ensemble machine learning algorithm that combines multiple weak models into a strong one. It aims to improve accuracy by focusing on errors from previous models.\n",
    "\n",
    "**How Boosting Works**\n",
    "\n",
    "- **Error Correction**: Boosting iteratively adds models to correct previous errors, focusing on misclassified data points.\n",
    "- **Weight Adjustment**: Increases weights for misclassified points and decreases for correctly classified ones, making the model focus on harder cases.\n",
    "- **Model Specialization**: Each new model becomes more specialized, enhancing overall ensemble accuracy.\n",
    "\n",
    "**Types of Boosting Algorithms**\n",
    "\n",
    "- **AdaBoost (Adaptive Boosting)**\n",
    "- **Gradient Boosting**\n",
    "- **XGBoost (Extreme Gradient Boosting)**\n",
    "\n",
    "Each varies in weight assignment and model building but follows the core concept of combining weak models to form a strong one.\n",
    "\n",
    "**Difference between Bagging and Boosting**\n",
    "\n",
    "- **Training Approach**: Bagging trains weak learners simultaneously, while Boosting does so sequentially, focusing on prior misclassifications.\n",
    "- **Weight Redistribution**: Boosting redistributes weights to improve focus on challenging data points.\n",
    "- **Use Cases**: Bagging is often used with high variance, low bias models (like decision trees), whereas Boosting is applied to low variance, high bias scenarios.\n",
    "- **Overfitting Risk**: Boosting can be more prone to overfitting compared to Bagging. This risk can be mitigated through hyperparameter tuning and regularization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5QhbpJ3iIOI"
   },
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "Gradient Boosting is a sequential modeling technique, aiming to correct the errors of previous models. It revolves around three key components: the additive model, loss function, and a weak learner.\n",
    "\n",
    "**Core Principles**\n",
    "\n",
    "- **Sequential Development**: Models are built one after another, each focusing on reducing the errors made by its predecessor.\n",
    "- **Numerical Optimization**: It interprets boosting as a numerical optimization of the loss function using Gradient Descent.\n",
    "\n",
    "**Application in Regression and Classification**\n",
    "\n",
    "- **Gradient Boosting Regressor**: Used when the target variable is continuous.\n",
    "- **Gradient Boosting Classifier**: Applied in classification tasks.\n",
    "- **Loss Function**: The key distinction between the regressor and classifier lies in their loss functions - Mean Squared Error (MSE) for regression and log-likelihood for classification.\n",
    "\n",
    "The objective of Gradient Boosting is to minimize the loss function by iteratively adding weak learners, tailored to the specific problem type (regression or classification).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lS5fSN6SjEQ1"
   },
   "source": [
    "### XGBoost\n",
    "\n",
    "XGBoost stands for Extreme Gradient Boosting and is an advanced form of gradient boosting. It iteratively builds an ensemble of models, with each new model focusing on correcting errors of previous ones.\n",
    "\n",
    "**How XGBoost Works**\n",
    "\n",
    "- **Error Correction**: Each iteration involves fitting a new model to the residual errors made by the last model.\n",
    "- **Objective Function**: Combines a loss function with a regularization term to minimize prediction errors and prevent overfitting.\n",
    "- **Model Ensemble**: The algorithm adds each new model to the ensemble and repeats until reaching the desired count.\n",
    "\n",
    "**Example Process Using XGBoost**\n",
    "\n",
    "1. **Initialize the Model**: Begin with a simple decision tree.\n",
    "2. **Make Predictions**: Use the model to predict training data, then compute residuals (differences between predictions and true labels).\n",
    "3. **Fit a New Tree**: Train a new decision tree on these residuals.\n",
    "4. **Combine Models**: Add this new tree to the ensemble, enhancing the overall model.\n",
    "5. **Iteration**: Repeat this process for a set number of iterations, continually improving the model.\n",
    "6. **Final Predictions**: Use the combined predictions of all trees for new data.\n",
    "\n",
    "XGBoost's strength lies in its ability to focus on misclassified points and use regularization, enhancing both accuracy and generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqg9v6lo15J7"
   },
   "source": [
    "### Classification Evaluation Metrics\n",
    "\n",
    "Evaluation metrics are crucial for assessing the performance of classification models in machine learning. Key metrics include F1 score, recall, precision, confusion matrix, and ROC AUC score.\n",
    "\n",
    "**F1 Score**\n",
    "- Combines precision and recall into a single value.\n",
    "- Expressed between 0 and 1, where 1 indicates perfect precision and recall.\n",
    "- Calculated as: $$ F1 = \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}} $$\n",
    "\n",
    "**Recall**\n",
    "- Important when false negatives have high costs (e.g., medical diagnosis).\n",
    "- Formula: $$ Recall = \\frac{TP}{TP + FN} $$\n",
    "\n",
    "**Precision**\n",
    "- Key when false positives have significant consequences (e.g., fraud detection).\n",
    "- Formula: $$ precision = \\frac{true\\ positive}{true\\ positive + false\\ positive} $$\n",
    "\n",
    "**Confusion Matrix**\n",
    "- Tabulates true positives, false positives, true negatives, and false negatives.\n",
    "\n",
    "|                      | Actual Positive      | Actual Negative      |\n",
    "|----------------------|----------------------|----------------------|\n",
    "| Predicted Positive   | True Positive (TP)   | False Positive (FP)  |\n",
    "| Predicted Negative   | False Negative (FN)  | True Negative (TN)   |\n",
    "\n",
    "**ROC AUC Score**\n",
    "- Measures a classifier's ability to differentiate between classes.\n",
    "- Calculated as the area under the ROC curve, plotting true positive rate vs false positive rate.\n",
    "- Formula: $$ ROC\\ AUC\\ Score = \\int_0^1 TPR(FPR^{-1}(t)) dt $$\n",
    "\n",
    "**Choosing the Right Metric**\n",
    "- **F1 Score**: Use when precision and recall are equally important.\n",
    "- **Recall**: Choose for high costs of missing positive cases.\n",
    "- **Precision**: Prefer when false positives have serious implications.\n",
    "- **Confusion Matrix**: Useful for a detailed performance overview.\n",
    "- **ROC AUC Score**: Optimal when class distinction is crucial.\n",
    "\n",
    "\n",
    "### Importance with respect to the business problem:\n",
    "\n",
    "Here we will be focusing more on Recall score than precision, as is noted in established publications [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10239051/#:~:text=In%20the%20telecommunication%20industry%2C%20research,an%20existing%20customer%20%5B10%5D.) acquiring customers costs atleast 5 times more than retaining existing ones in telecoms so Precision scores will not have a heavy importance unless they exceed the Recall score by atleast 5x.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObhvEqGv15J8"
   },
   "source": [
    "### Model Evaluation Function: `evaluate_models()`\n",
    "\n",
    "The `evaluate_models()` function is designed to assess the performance of various classification models on a dataset. \n",
    "\n",
    "**Function Features**\n",
    "\n",
    "- **Inputs**: Accepts a machine learning model, training, and testing data.\n",
    "- **Outputs**: Returns metrics like F1 Score, Recall Score, Confusion Matrix, and AUC for both training and testing sets.\n",
    "\n",
    "**Utility**\n",
    "\n",
    "- **Model Comparison**: Facilitates comparison across different classification models.\n",
    "- **Best Model Selection**: Aids in selecting the most effective model for a specific problem.\n",
    "- **Data Storage**: Outputs are stored in a pandas DataFrame for further analysis and comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "jAXhpTUEZ-2v"
   },
   "outputs": [],
   "source": [
    "# function modelling\n",
    "#Columns needed to compare metrics\n",
    "comparison_columns = ['Model_Name', 'Train_F1score', 'Train_Recall', 'Test_F1score', 'Test_Recall']\n",
    "\n",
    "comparison_df = pd.DataFrame()\n",
    "\n",
    "def evaluate_models(model_name, model_defined_var, X_train, y_train, X_test, y_test):\n",
    "  ''' This function predicts and evaluates various models for clasification'''\n",
    "  \n",
    "  # train predictions\n",
    "  y_train_pred = model_defined_var.predict(X_train)\n",
    "  # train performance\n",
    "  train_f1_score = f1_score(y_train,y_train_pred)\n",
    "  train_recall = recall_score(y_train, y_train_pred)\n",
    "\n",
    "  # test predictions\n",
    "  y_pred = model_defined_var.predict(X_test)\n",
    "  # test performance\n",
    "  test_f1_score = f1_score(y_test,y_pred)\n",
    "  test_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "  # Printing performance\n",
    "  print(\"Train Results\")\n",
    "  print(f'F1 Score: {train_f1_score}')\n",
    "  print(f'Recall Score: {train_recall}')\n",
    "  print(f'Confusion Matrix: \\n{confusion_matrix(y_train, y_train_pred)}')\n",
    "  print(f'Area Under Curve: {roc_auc_score(y_train, y_train_pred)}')\n",
    "\n",
    "  print(\" \")\n",
    "\n",
    "  print(\"Test Results\")\n",
    "  print(f'F1 Score: {test_f1_score}')\n",
    "  print(f'Recall Score: {test_recall}')\n",
    "  print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}')\n",
    "  print(f'Area Under Curve: {roc_auc_score(y_test, y_pred)}')\n",
    "\n",
    "  \n",
    "  #Saving our results\n",
    "  global comparison_columns\n",
    "\n",
    "  metric_scores = [model_name, train_f1_score, train_recall, test_f1_score, test_recall]\n",
    "  final_dict = dict(zip(comparison_columns,metric_scores))\n",
    "\n",
    "  return final_dict\n",
    "\n",
    "\n",
    "#function to create the comparison table\n",
    "final_list = []\n",
    "def add_dic_to_final_df(final_dict):\n",
    "  global final_list\n",
    "  final_list.append(final_dict)\n",
    "  global comparison_df\n",
    "  comparison_df = pd.DataFrame(final_list, columns= comparison_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7-ur5w915J8"
   },
   "source": [
    "The above code defines two functions for evaluating machine learning models for classification. The first function is evaluate_models() which takes a model name, a defined machine learning model variable, training and testing data, and evaluates the model's performance using the F1 score, recall score, confusion matrix, and area under the curve (AUC) score. It then prints the results of the model's performance on the training and testing datasets. Finally, it creates a dictionary of the evaluation metrics for the model and returns it.\n",
    "\n",
    "The second function is add_dic_to_final_df() which takes the dictionary returned from the evaluate_models() function and appends it to a list of all models evaluated. It then creates a pandas DataFrame from the list and returns it. The DataFrame contains the evaluation metrics for all the models evaluated so far, including the model name, training F1 score, training recall score, testing F1 score, and testing recall score.\n",
    "\n",
    "The comparison_columns variable is a list of the column names for the comparison_df DataFrame. It is used to ensure that the DataFrame columns are always in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "mC-rzryIZ-2v",
    "outputId": "bdc40228-71ad-40f0-ec44-32badd58abfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn Value\n",
       "0    0.687235\n",
       "1    0.312765\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Churn in training data\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "kULbYj1WZ-2v",
    "outputId": "8b6621e4-2d2a-436c-96ff-5429d14710fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn Value\n",
       "0    0.821501\n",
       "1    0.178499\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Churn in test data\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJQRfdRO15J8"
   },
   "source": [
    "To handle the heavy imbalance we find in our dataset, we have used the churn rate as weights to give more importance to the minority class during the model training process.\n",
    "\n",
    "To do this, we can calculate the churn rate (e.g., by dividing the number of churned customers by the total number of customers) and use it as a weight in the loss function during model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "zBTMjBgSZ-2v"
   },
   "outputs": [],
   "source": [
    "# Let's calculate the churn rate for data and store it as dict\n",
    "w=y_train.value_counts(normalize=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "F8l1pyBzZ-2v",
    "outputId": "22035971-3d60-4a09-ce75-3bf8a221e1c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6872351803858653, 1: 0.31276481961413466}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number of Dependents\n",
       "0.0    437828\n",
       "1.0     81616\n",
       "4.0     39616\n",
       "2.0     21125\n",
       "3.0     16027\n",
       "7.0     15458\n",
       "6.0     15119\n",
       "8.0     13623\n",
       "9.0     13023\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Number of Dependents'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Creating an instance of SimpleImputer with strategy as 'most_frequent'\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Fitting the imputer on the X_train data\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# Transforming both X_train and X_test data\n",
    "X_train_imputed = imputer.transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Optionally, if you want to put the imputed data back into a DataFrame:\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "zso3lJtgZ-2v",
    "outputId": "490d286d-b3f4-4433-d28d-4ac1bb1377b4"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "lg2 = LogisticRegression(random_state=13, class_weight=w)\n",
    "# fit it\n",
    "lg2.fit(X_train_imputed,y_train)\n",
    "\n",
    "model_snapshot(\"fcTel2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "32uRyLlRZ-2v",
    "outputId": "5895d80b-d068-437f-a84f-c27b2af6be1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results\n",
      "F1 Score: 0.036627241510873716\n",
      "Recall Score: 0.018939892147836382\n",
      "Confusion Matrix: \n",
      "[[16590   116]\n",
      " [ 7459   144]]\n",
      "Area Under Curve: 0.5059981395373445\n",
      " \n",
      "Test Results\n",
      "F1 Score: 0.03387663790348354\n",
      "Recall Score: 0.017773306505700873\n",
      "Confusion Matrix: \n",
      "[[13630    94]\n",
      " [ 2929    53]]\n",
      "Area Under Curve: 0.5054619957186038\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "logistic_results = evaluate_models(\"Logistic Regression\", lg2, X_train_imputed, y_train, X_test_imputed, y_test)\n",
    "add_dic_to_final_df(logistic_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "l_x9tisdZ-2w",
    "outputId": "74c3ad02-43b1-4991-8b47-e36a01f217ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results\n",
      "F1 Score: 0.9939874463164851\n",
      "Recall Score: 0.9893463106668421\n",
      "Confusion Matrix: \n",
      "[[16696    10]\n",
      " [   81  7522]]\n",
      "Area Under Curve: 0.9943738616664749\n",
      " \n",
      "Test Results\n",
      "F1 Score: 0.45925361766945927\n",
      "Recall Score: 0.4044265593561368\n",
      "Confusion Matrix: \n",
      "[[12660  1064]\n",
      " [ 1776  1206]]\n",
      "Area Under Curve: 0.663449070992554\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "random_f = RandomForestClassifier(n_estimators=20, class_weight=w, random_state=7)\n",
    "random_f.fit(X_train_imputed, y_train)\n",
    "\n",
    "randomf_results = evaluate_models(\"Random Forest\", random_f, X_train_imputed, y_train, X_test_imputed, y_test)\n",
    "add_dic_to_final_df(randomf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHIxg_Lq15J9"
   },
   "source": [
    "### XG Boost Training\n",
    "\n",
    "XGBoost is a robust library for gradient boosting in supervised machine learning. Known for its efficiency and flexibility, it's a favored choice in many machine learning competitions.\n",
    "\n",
    "**D Matrix in XGBoost**\n",
    "\n",
    "- **Purpose**: Serves as a data structure to store and efficiently access input data during training.\n",
    "- **Structure**: Acts as a wrapper around input data, which can be in the form of NumPy arrays or Pandas DataFrames.\n",
    "- **Advantages**:\n",
    "  - **Efficient Data Access**: Crucial for handling large datasets.\n",
    "  - **Additional Features**: Handles missing values, splits data into training and validation sets.\n",
    "  - **Ease of Use**: Simplifies the process of feeding data into the XGBoost model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "G0oToz7ZZ-2w",
    "outputId": "4f95287b-8c92-4ff0-9dae-d3d602b2f4a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results\n",
      "F1 Score: 0.8261832272349847\n",
      "Recall Score: 0.7852163619623833\n",
      "Confusion Matrix: \n",
      "[[15827   879]\n",
      " [ 1633  5970]]\n",
      "Area Under Curve: 0.8663002676566376\n",
      " \n",
      "Test Results\n",
      "F1 Score: 0.4899047619047619\n",
      "Recall Score: 0.4312541918175721\n",
      "Confusion Matrix: \n",
      "[[12742   982]\n",
      " [ 1696  1286]]\n",
      "Area Under Curve: 0.6798503544339973\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert training and test sets to DMatrix\n",
    "dtrain = xgb.DMatrix(X_train_imputed, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_imputed, label=y_test)\n",
    "\n",
    "# Train initial model\n",
    "params = {'objective': 'multi:softmax', 'num_class': 2}\n",
    "num_rounds = 30\n",
    "xgbmodel = xgb.train(params, dtrain, num_rounds)\n",
    "model_snapshot(\"fcTel2\")\n",
    "\n",
    "\n",
    "xgb_results = evaluate_models(\"XGB\", xgbmodel, dtrain, y_train, dtest, y_test)\n",
    "add_dic_to_final_df(xgb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "ujXnaqb4Z-2w",
    "outputId": "2d201a8c-58d8-4662-dfb3-3ec84743097c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Train_F1score</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Test_F1score</th>\n",
       "      <th>Test_Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>0.033877</td>\n",
       "      <td>0.017773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.993987</td>\n",
       "      <td>0.989346</td>\n",
       "      <td>0.459254</td>\n",
       "      <td>0.404427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.826183</td>\n",
       "      <td>0.785216</td>\n",
       "      <td>0.489905</td>\n",
       "      <td>0.431254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model_Name  Train_F1score  Train_Recall  Test_F1score  Test_Recall\n",
       "0  Logistic Regression       0.036627      0.018940      0.033877     0.017773\n",
       "1        Random Forest       0.993987      0.989346      0.459254     0.404427\n",
       "2                  XGB       0.826183      0.785216      0.489905     0.431254"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the comparison df\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCbijPMv15J-"
   },
   "source": [
    "### **Future work Hyperparameter tuning with XGBoost**\n",
    "\n",
    "Perform hyperparameter tuning on the XGBoost model using a grid search approach.\n",
    "hyperparamters to be considered include:\n",
    "\n",
    "* max_depth: the maximum depth of each tree in the ensemble\n",
    "* learning_rate: the learning rate for gradient boosting\n",
    "* n_estimators: the number of trees in the ensemble\n",
    "* min_child_weight: the minimum weight required in a child node to continue splitting\n",
    "* subsample: the fraction of samples used for each tree\n",
    "* colsample_bytree: the fraction of features used for each tree\n",
    "* You can define a dictionary of hyperparameter values to search over, and then pass it to the param_grid parameter of the GridSearchCV function.\n",
    "\n",
    "Evaluate the tuned model\n",
    "Evaluate the performance of the tuned model on the testing data using the sklearn.metrics module.\n",
    "\n",
    "\n",
    "Different hyperparameter optimization technique, such as random search or Bayesian optimization could also be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "572xabmveMsQ"
   },
   "source": [
    "## Data Drift Monitoring\n",
    "\n",
    "### Why Is Drift Important?\n",
    "\n",
    "Drift in machine learning signifies changes in data or its relationship with target labels, potentially degrading model performance. Detecting drift is crucial in production environments to maintain accuracy, as it indicates the need for model adjustment or retraining.\n",
    "\n",
    "- **Not All Changes Are Drift**: Regular periodic changes (like seasonal variations) are usually not considered drift.\n",
    "- **Indication of Performance Deterioration**: Drift often signals a decline in model performance, especially when labels are unknown post-prediction.\n",
    "\n",
    "### Types of Drift\n",
    "\n",
    "There are two primary types of drift in machine learning:\n",
    "\n",
    "- **Data Drift**: Changes in the data distribution. For instance, socio-economic initiatives altering education levels can affect income distribution but not the correlation between education and income.\n",
    "\n",
    "- **Concept Drift**: Shifts in the relationship between data and labels. For example, job market changes making experience more valuable than academic degrees for certain jobs, altering the education-income correlation.\n",
    "\n",
    "Both types of drift can necessitate model retraining or updates.\n",
    "\n",
    "### Handling Drift\n",
    "\n",
    "When facing drift:\n",
    "\n",
    "1. **Identify the Change**: Determine if the drift is in features, labels, or predictions.\n",
    "2. **Manual Data Exploration**: Investigate the root cause of changes to understand their impact.\n",
    "3. **Retrain Your Model**: Address both data and concept drift by retraining with new, relevant data. This might require additional resources or be delayed if new labels are unavailable.\n",
    "\n",
    "Retraining is essential for concept drift but can also be beneficial for data drift, especially if it affects label distribution.\n",
    "\n",
    "\n",
    "\n",
    "Reference: [Deepchecks Documentation](https://docs.deepchecks.com/stable/user-guide/general/drift_guide.html#what-is-distribution-drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "FsPZPOfpZ-2x"
   },
   "outputs": [],
   "source": [
    "# Define categorical and continuous columns\n",
    "pred_cat_cols=[\n",
    "       'Gender_Female', 'Gender_Male', 'Gender_Not Specified', 'Gender_Other',\n",
    "       'Married_No', 'Married_Not Specified', 'Married_Yes', 'Dependents_No',\n",
    "       'Dependents_Not Specified', 'Dependents_Yes', 'offer_A', 'offer_B',\n",
    "       'offer_C', 'offer_D', 'offer_E', 'offer_F', 'offer_G', 'offer_H',\n",
    "       'offer_I', 'offer_J', 'offer_No Offer', 'Referred a Friend_No',\n",
    "       'Referred a Friend_Yes', 'Phone Service_No', 'Phone Service_Yes',\n",
    "       'Multiple Lines_No', 'Multiple Lines_None', 'Multiple Lines_Yes',\n",
    "       'Internet Service_No', 'Internet Service_Yes', 'Internet Type_Cable',\n",
    "       'Internet Type_DSL', 'Internet Type_Fiber Optic', 'Internet Type_None',\n",
    "       'Internet Type_Not Applicable', 'Online Security_No',\n",
    "       'Online Security_Yes', 'Online Backup_No', 'Online Backup_Yes',\n",
    "       'Device Protection Plan_No', 'Device Protection Plan_Yes',\n",
    "       'Premium Tech Support_No', 'Premium Tech Support_Yes',\n",
    "       'Streaming TV_No', 'Streaming TV_Yes', 'Streaming Movies_No',\n",
    "       'Streaming Movies_Yes', 'Streaming Music_No', 'Streaming Music_Yes',\n",
    "       'Unlimited Data_No', 'Unlimited Data_None', 'Unlimited Data_Yes',\n",
    "       'Payment Method_Bank Withdrawal', 'Payment Method_Credit Card',\n",
    "       'Payment Method_Wallet Balance']\n",
    "\n",
    "pred_cts_cols=['Age', 'Number of Dependents', 'roam_ic', 'roam_og', 'loc_og_t2t',\n",
    "       'loc_og_t2m', 'loc_og_t2f', 'loc_og_t2c', 'std_og_t2t', 'std_og_t2m',\n",
    "       'std_og_t2f', 'std_og_t2c', 'isd_og', 'spl_og', 'og_others',\n",
    "       'loc_ic_t2t', 'loc_ic_t2m', 'loc_ic_t2f', 'std_ic_t2t', 'std_ic_t2m',\n",
    "       'std_ic_t2f', 'std_ic_t2o', 'spl_ic', 'isd_ic', 'ic_others',\n",
    "       'total_rech_amt', 'total_rech_data', 'vol_4g', 'vol_5g', 'arpu_5g',\n",
    "       'arpu_4g', 'arpu', 'aug_vbc_5g', 'Number of Referrals',\n",
    "       'Streaming Data Consumption', 'Satisfaction Score', 'total_recharge']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdfyIpeV15J-"
   },
   "source": [
    "The below code defines a function called check_data_drift() that checks for data drifts between two datasets, ref_df and cur_df, based on a set of predictors. The function uses the dataduit library to create two datasets, ref_dataset and cur_dataset, based on the reference and current dataframes, respectively. The features and cat_features parameters are set for each dataset based on the ref_features, cur_features, ref_cat_features, and cur_cat_features lists, which are generated based on the intersection of predictors and the columns of the two dataframes.\n",
    "\n",
    "The function then creates a suite object, which contains two tests for data drift: WholeDatasetDrift() and TrainTestFeatureDrift(). The WholeDatasetDrift() test checks for overall drift in the entire dataset, while the TrainTestFeatureDrift() test checks for drift in specific features between the reference and current datasets. The add_condition_overall_drift_value_less_than() and add_condition_drift_score_less_than() methods set the threshold for acceptable drift to 0.2 and 0.1, respectively.\n",
    "\n",
    "The suite is then run using the reference and current datasets as train_dataset and test_dataset, respectively, and the results are stored in an r object. If any checks did not run or did not pass, the retrain variable is set to True, indicating that the model may need to be retrained. Finally, the function saves the results of the data drift analysis as an HTML report in the Output directory with a filename based on the job_id parameter.\n",
    "\n",
    "The function returns a dictionary with two keys: report, which contains the r object with the results of the data drift analysis, and retrain, which is a boolean value indicating whether the model needs to be retrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "BSdh_6o2Z-2x"
   },
   "outputs": [],
   "source": [
    "def check_data_drift(ref_df:pd.DataFrame, cur_df:pd.DataFrame, predictors:list, job_id:str):\n",
    "    \"\"\"\n",
    "    Check for data drifts between two datasets and decide whether to retrain the model. \n",
    "    A report will be saved in the results directory.\n",
    "    :param ref_df: Reference dataset\n",
    "    :param cur_df: Current dataset\n",
    "    :param predictors: Predictors to check for drifts\n",
    "    :param target: Target variable to check for drifts\n",
    "    :param job_id: Job ID\n",
    "    :return: boolean\n",
    "    \"\"\"\n",
    "    ref_features = [col for col in predictors if col in ref_df.columns]\n",
    "    cur_features = [col for col in predictors if col in cur_df.columns]\n",
    "    ref_cat_features = [col for col in pred_cat_cols if col in ref_df.columns]\n",
    "    cur_cat_features = [col for col in pred_cat_cols if col in cur_df.columns]\n",
    "    ref_dataset = Dataset(ref_df,  features=ref_features, cat_features=ref_cat_features)\n",
    "    cur_dataset = Dataset(cur_df, features=cur_features, cat_features=cur_cat_features)\n",
    "    \n",
    "    suite = Suite(\"data drift\",\n",
    "        WholeDatasetDrift().add_condition_overall_drift_value_less_than(0.2), #0.2 \n",
    "        TrainTestFeatureDrift().add_condition_drift_score_less_than(0.2), #0.1   \n",
    "        )\n",
    "    r = suite.run(train_dataset=ref_dataset, test_dataset=cur_dataset)\n",
    "    retrain = (len(r.get_not_ran_checks())>0) or (len(r.get_not_passed_checks())>0)\n",
    "    \n",
    "    # try:\n",
    "    #     r.save_as_html(f\"../reports/{job_id}_data_drift_report.html\")\n",
    "    #     print(\"[INFO] Data drift report saved as {}\".format(f\"{job_id}_data_drift_report.html\"))\n",
    "    # except Exception as e:\n",
    "    #     print(f\"[WARNING][DRIFTS.check_DATA_DRIFT] {traceback.format_exc()}\")\n",
    "    return {\"report\": r, \"retrain\": retrain}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "__Oh0gxVZ-2x"
   },
   "outputs": [],
   "source": [
    "# Defining the preprocessing steps for test data\n",
    "def preprocess_steps(data):\n",
    "    df=data.copy()\n",
    "    drop_cols=['Customer ID', 'Quarter', 'Quarter of Joining', 'Month',\n",
    "       'Month of Joining', 'zip_code','Location ID', 'Service ID',\n",
    "       'state', 'county', 'timezone', 'area_codes', 'country', 'latitude',\n",
    "       'longitude','Status ID']\n",
    "    df=df.drop(columns=drop_cols)\n",
    "    processed_data=df.copy()\n",
    "    processed_data[encoded_features] = encoder.transform(processed_data[categorical_cols])\n",
    "    processed_data=processed_data.drop(categorical_cols,axis=1)\n",
    "    processed_data[cts_cols]  = scaler.transform(processed_data[cts_cols]) \n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "AdLiM35qZ-2x"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of train for reference\n",
    "ref_check_data=X_train_imputed.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMnZm0MdZ-2y"
   },
   "source": [
    "### Inference Pipeline with and without Label Availability\n",
    "\n",
    "In machine learning, deploying models for predictions on new data involves different approaches based on label availability.\n",
    "\n",
    "#### Case 1: Label Not Available\n",
    "Without labels, model drift can't be assessed, and the model can't be retrained. The inference pipeline here includes:\n",
    "\n",
    "- **Preprocessing**: Apply the same preprocessing steps to new data as were used for training data.\n",
    "- **Prediction**: Use the trained model to predict on preprocessed new data.\n",
    "- **Data Drift Check**: Monitor for any significant data drift compared to training data, which might impact prediction accuracy.\n",
    "\n",
    "#### Case 2: Label Available\n",
    "With labels, it's possible to check for both data and model drift and consider retraining. The pipeline involves:\n",
    "\n",
    "- **Preprocessing**: Same as in Case 1, preprocess the new data.\n",
    "- **Data Drift Check**: Compare new data against training data to detect significant drift.\n",
    "- **Model Retraining**: If drift is detected, consider retraining the model.\n",
    "- **Prediction**: Use either the existing or the retrained model for predictions.\n",
    "\n",
    "### Importance of Drift Checks\n",
    "- **Assumption Validation**: Machine learning models operate under the assumption that training and new data distributions are similar.\n",
    "- **Performance Maintenance**: Identifying and addressing data or model drift ensures sustained model accuracy on new data.\n",
    "\n",
    "The inference pipeline is key in real-world applications, ensuring that models remain accurate and effective over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "5W9uUrowZ-2x"
   },
   "outputs": [],
   "source": [
    "def inference_pipeline(inference_data,reference_data,job_id,predictors_cols):\n",
    "    \n",
    "\n",
    "\n",
    "    #data preprocessing\n",
    "    clean_inf_data=preprocess_steps(inference_data)\n",
    "\n",
    "    #data drift\n",
    "    data_drift=check_data_drift(ref_df=reference_data, cur_df=clean_inf_data, predictors=predictors_cols,  job_id=job_id)\n",
    "    print(f\"Data Drift Retrain: {data_drift['retrain']}\")\n",
    "\n",
    "    return data_drift\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "m4gbSSj9Z-2y",
    "outputId": "87c79d4e-fa5e-49f6-fbe0-5da4a99be8c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Drift Retrain: False\n"
     ]
    }
   ],
   "source": [
    "model_snapshot(\"fcTel2\")\n",
    "d1_drift=inference_pipeline(inference_data=prediction_data[prediction_data.columns[:-1]],reference_data=ref_check_data,job_id='1cbhja2',predictors_cols=pred_cat_cols+pred_cts_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_7DsLU6Z-2y"
   },
   "source": [
    "No data drift!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                               float64\n",
      "Number of Dependents              float64\n",
      "arpu                              float64\n",
      "roam_ic                           float64\n",
      "roam_og                           float64\n",
      "                                   ...   \n",
      "Unlimited Data_Yes                float64\n",
      "Unlimited Data_nan                float64\n",
      "Payment Method_Bank Withdrawal    float64\n",
      "Payment Method_Credit Card        float64\n",
      "Payment Method_Wallet Balance     float64\n",
      "Length: 93, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pred_processed_data = preprocess_steps(prediction_data.drop(columns=['Churn Value', 'age_bucket']))\n",
    "\n",
    "# Check data types of columns in pred_processed_data\n",
    "print(pred_processed_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "oW7LH9zQZ-2y"
   },
   "outputs": [],
   "source": [
    "# Converting the preprocessed data to DMatrix format for XGBoost\n",
    "d_pred_processed_data = xgb.DMatrix(pred_processed_data)\n",
    "\n",
    "# Making predictions using the XGBoost model\n",
    "predictions = xgbmodel.predict(d_pred_processed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO1T4DxKZ-2y"
   },
   "source": [
    "Lets compare predictions and actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "c0I6G4UfZ-2y"
   },
   "outputs": [],
   "source": [
    "# Saving the actual labels\n",
    "pred_label=prediction_data['Churn Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "u45hgTcUZ-2y",
    "outputId": "acf231e2-5fc7-4884-dd6f-1f0a6c827b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[21402  2112]\n",
      " [  615  1489]]\n",
      "Area Under Curve: 0.8089403942186696\n"
     ]
    }
   ],
   "source": [
    "print(f'Confusion Matrix: \\n{confusion_matrix(pred_label, predictions)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(pred_label, predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8RlvR_yZ-2y"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "* The confusion matrix shows that the model correctly predicted 21402 instances of non-churn and 1489 instances of churn. However, it incorrectly predicted 2112 instances of churn and 615 instances of non-churn.\n",
    "\n",
    "* The area under the curve (AUC) is 0.8089, which indicates that the model has a moderate level of accuracy in distinguishing between churn and non-churn customers.\n",
    "\n",
    "* False negatives occur when the model predicts that a customer will not churn, but in reality, the customer does churn. In this case, the model has 615 false negatives, which means that it predicted 615 customers to be non-churners, but they actually churned. This is a concern because it means that the model is not able to accurately identify all of the customers who are at risk of churning, and this could result in missed opportunities to retain these customers.\n",
    "\n",
    "* False positives occur when the model predicts that a customer will churn, but in reality, the customer does not churn. In this case, the model has 2112 false positives, which means that it predicted 2112 customers to be churners, but they actually did not churn. This is also a concern because it could result in unnecessary retention efforts being directed towards customers who are not at risk of churning, which could be a waste of resources.  Yet these results are not as concerning as preventing churn is ultimately the most cost effectively solution than unecessarily allowing customers to churn out of cost concerns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MONYJU8W15KB"
   },
   "source": [
    "## Future potential work \n",
    "\n",
    "We can improve the results by retraining the model "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (telco_project)",
   "language": "python",
   "name": "telco_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9054e5812adb29eebbcd6b680e8ef1afc4fe6e00a75ff130e735bd95b5b32301"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
